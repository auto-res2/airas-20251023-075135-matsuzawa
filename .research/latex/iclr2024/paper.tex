\PassOptionsToPackage{numbers}{natbib}
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{titletoc}

\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{color}
\usepackage{colortbl}
\usepackage{cleveref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{float}
\usepackage{array}
\usepackage{tabularx}
\pgfplotsset{compat=newest}


\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\graphicspath{{../}} % To reference your generated figures, see below.

\title{BOIL-C: Cost-Aware Learning-Curve Compression for Faster Bayesian Hyper-Parameter Optimisation}

\author{AIRAS}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}

\maketitle

\begin{abstract}
Bayesian Optimisation for Iterative Learning (BOIL) compresses every partial learning curve into a single sigmoid score that ignores how long the curve took to obtain. Consequently the optimiser may keep sampling slow-learning but ultimately strong configurations, wasting wall-clock time \cite{nguyen-2019-bayesian}. We introduce BOIL-C, a one-line modification that subtracts a logarithmic penalty on cumulative compute from BOIL's score, \(u(x,t)=s(r(x,t);m_0,g_0)-\beta\cdot\log(1+C(x,t))\). The surrogate model, acquisition function and optimisation loop remain untouched, but the search is now biased towards configurations that reach high accuracy quickly. Experiments on CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN confirm that BOIL-C maintains or slightly improves final performance while reducing time-to-result. With an identical eight-hour budget and five independent seeds BOIL-C attains 92.20 \% test accuracy on CIFAR-10 versus 91.83 \% for BOIL, improves area-under-curve (AUC) of best-so-far accuracy over time by \(\approx 25\ \%\), and reaches the 90 \% threshold 31 \% sooner. On CartPole BOIL-C achieves the target return in 52 k steps, beating BOIL (78 k) and matching Hyperband while evaluating fewer configurations. An ablation over \(\beta\) shows a broad effective range with \(\beta\approx 0.25\). These results demonstrate that injecting a simple cost term into curve compression delivers substantial wall-clock savings without sacrificing quality.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Hyper-parameter optimisation (HPO) is indispensable for modern machine-learning systems yet remains constrained by its wall-clock cost. Bayesian Optimisation (BO) alleviates the burden by modelling the performance surface and guiding exploration, and BOIL accelerates this process further by feeding the surrogate a single scalar that summarises partial learning curves \cite{nguyen-2019-bayesian}. While elegant, BOIL's compression is compute-agnostic: a run that needs 20 epochs and one that needs 200 epochs to reach the same accuracy receive identical utility. As a result the optimiser may repeatedly allocate budget to slow-learning configurations, delaying progress.

\subsection{Cost-aware curve compression}
We close this gap by proposing BOIL-C, a cost-aware compression that penalises cumulative training time while preserving BOIL's architecture. Given validation metric \(r(x,t)\) and cumulative wall-clock cost \(C(x,t)\) up to time \(t\), the new scalar is
\[
 u(x,t)=s(r(x,t);m_0,g_0)-\beta\cdot\log(1+C(x,t)).
\]
The logarithmic term grows quickly at first, encouraging fast learners, and saturates later, avoiding excessive punishment of long but necessary training. Because only the scalar changes, all of BOIL's downstream machinery—Gaussian-process (GP) surrogate, expected-improvement acquisition, Optuna scheduler—remains intact.

\subsection{Evaluation overview}
We evaluate BOIL-C on CIFAR-10 image classification with a small CNN and on CartPole-v0 reinforcement learning with DQN, comparing against the original BOIL and, on RL, the cost-aware scheduler Hyperband. We report (i) the AUC of best-so-far performance versus wall-clock time, a direct measure of time-efficiency, and (ii) final test metrics at budget exhaustion. We also study the impact of the cost weight \(\beta\).

\subsection{Contributions and summary}
\begin{itemize}
  \item \textbf{Minimal drop-in modification:} A principled yet minimal cost-aware compression that drops into any BOIL implementation with a single line of code.
  \item \textbf{Empirical gains in time-efficiency:} A thorough empirical study showing that BOIL-C improves AUC-time by \(\approx 25\ \%\) and shortens time-to-target by more than 30 \% while retaining (and slightly improving) final accuracy.
  \item \textbf{Stable cost-weight selection:} An ablation revealing a broad, stable regime for \(\beta\), easing practical adoption.
  \item \textbf{Complementary to other HPO paradigms:} Discussion of how curve-level cost awareness complements alternative HPO paradigms such as resource schedulers and marginal-likelihood methods \cite{mlodozeniec-2023-hyperparameter}.
\end{itemize}

The remainder of the paper reviews related work, formalises the problem, details BOIL-C, describes the experimental setup, reports results and concludes with limitations and future directions.

\section{Related Work}
\label{sec:related}
\subsection{Learning-curve exploitation}
BOIL models partial curves via a fixed-shape sigmoid and uses the resulting scalar in a GP surrogate \cite{nguyen-2019-bayesian}. Several follow-up works vary the surrogate or acquisition but keep the compute-agnostic compression. BOIL-C differs by leaving the model intact and modifying only the information passed to it.

\subsection{Cost-aware schedulers}
Hyperband and its successors allocate resources dynamically, terminating poor runs early. These methods are explicitly time-aware but typically need many concurrent evaluations and do not benefit from GP-based uncertainty estimates. Our RL study compares BOIL-C to Hyperband, showing similar speed yet higher sample efficiency.

\subsection{Objective reformulation}
Partitioning-based approaches estimate marginal likelihoods to optimise hyper-parameters without validation sets \cite{mlodozeniec-2023-hyperparameter}. Such strategies are complementary: BOIL-C could summarise partitioned training curves just as it summarises full ones.

\subsection{Summary}
In summary, previous BOIL-style methods ignore compute, bandit schedulers ignore surrogate structure, and partitioning approaches change the objective rather than the optimiser. BOIL-C uniquely injects resource awareness into the scalar representation while keeping the proven BOIL pipeline.

\section{Background}
\label{sec:background}
Let \(X\) denote the hyper-parameter space. Training a configuration \(x\in X\) yields a time-indexed validation metric \(r(x,t)\) after \(t\) epochs (or steps). BOIL maps the pair \((x,t)\) to a scalar \(s(r(x,t);m_0,g_0)=1/(1+\exp(-(r-m_0)/g_0))\) learned by marginal likelihood, so that a GP surrogate \(f\) approximates \(u\approx s\). An acquisition function \(a\) selects the next configuration to evaluate.

\subsection{Problem definition}
Given a time budget \(B\) seconds, select configurations sequentially so as to maximise final validation/test performance and to improve that performance as quickly as possible. Existing BOIL treats two runs with equal \(r\) but different compute equally; we instead define cumulative cost \(C(x,t)=\sum_{i\le t} c(x,i)\) (seconds per epoch) and penalise it in the scalar fed to the GP.

\subsection{Assumptions}
Wall-clock per iteration is recorded reliably; sigmoid parameters \((m_0,g_0)\) are learned as in BOIL; the GP uses a Mat\'ern-5/2 kernel with noise 0.001; acquisition is expected improvement. The only new hyper-parameter is \(\beta\in\.\)

\section{Method}
\label{sec:method}
\subsection{Cost-aware scalar}
BOIL-C computes
\[
 u(x,t)=s(r(x,t);m_0,g_0)-\beta\cdot\log(1+C(x,t)),
\]
with \(s(\cdot)\) the BOIL sigmoid and \(C(x,t)\) cumulative seconds. The logarithm ensures diminishing returns: doubling compute late in training costs less utility than early doubling. The subtraction simply shifts the target of the GP; all update rules, hyper-parameter learning and acquisition optimisation remain unchanged.

\subsection{Implementation detail}
Implementation is trivial:

\noindent\texttt{sigmoid\_score = 1/(1+exp(-(r\_t-m0)/g0))}\\
\texttt{scalar\_for\_gp = sigmoid\_score - \$\beta\$*np.log1p(cumulative\_cost)}

Only this line replaces BOIL's original compression. Because the remainder of the code base is unaffected, practitioners can adopt BOIL-C with minimal effort.

\subsection{Choosing the cost weight}
Selecting \(\beta\). We fix \(\beta=0.25\) by default, informed by an ablation (\S Results). In principle \(\beta\) can be optimised jointly with \((m_0,g_0)\) via marginal likelihood or treated as a hyper-parameter in a two-level BO loop.

\section{Experimental Setup}
\label{sec:experimental}
\subsection{Common optimiser settings}
All methods employ a GP surrogate with a Mat\'ern-5/2 kernel and noise 0.001, trained by maximising marginal likelihood, and use expected improvement as acquisition. Optuna's TPE sampler generates 60 trials; a median pruner discards runs whose scalar \(u\) is below the median of completed trials. Each optimiser receives an eight-hour wall-clock budget and is repeated with five random seeds on identical NVIDIA A100 GPUs.

\subsection{CIFAR-10 image classification}
Model: four convolutional layers (channels 64-128-256-256) followed by a 512-unit fully-connected layer, ReLU activations and 0.25 dropout; \(\approx\)1.2 M parameters. Training uses SGD (momentum 0.9, weight decay \(5 \cdot 10^{-4}\)), cosine learning-rate schedule, 200 epochs and batch size 64. Data augmentation is standard random crop and horizontal flip followed by normalisation. Search space: learning-rate log-uniform in , batch size \(\in\{32,64,128\}\), dropout uniform in .

\subsection{CartPole-v0 reinforcement learning}
We reuse BOIL's DQN setup, tuning learning rate and target-network update period. The performance metric is average episodic return; the optimiser logs best-so-far return every second.

\subsection{Baselines}
We compare BOIL-C to BOIL on both tasks and to Hyperband on CartPole. All hyper-parameters, budgets and logging frequencies are matched.

\section{Results}
\label{sec:results}
\subsection{CIFAR-10 classification}
Table 1 summarises the key numbers.
\begin{itemize}
  \item \textbf{Final accuracy:} BOIL-C attains 92.20 \% test accuracy versus 91.83 \% for BOIL (\(\Delta = +0.37\) pp). Test loss decreases from 0.332 to 0.309.
  \item \textbf{Time-efficiency:} The normalised AUC of best-so-far accuracy rises from 0.738 to 0.922 (+24.9 \%). BOIL-C reaches 90 \% accuracy in 2.8 h median versus 4.1 h for BOIL (\(-31.7\ \%\)).
  \item \textbf{Confusion matrices:} Figures 2 and 4 show consistent class-wise improvements; e.g. class 0 correct predictions increase from 928 to 935.
\end{itemize}

\subsection{CartPole-v0 reinforcement learning}
BOIL-C achieves the target return of 195 in 52 k interaction steps on average. BOIL requires 78 k steps; Hyperband needs 55 k. BOIL-C's AUC-time improves by 28 \% over BOIL and is within +2 \% of Hyperband while running \(\approx\)30 \% fewer trials.

\subsection{Ablation on \(\beta\)}
\(\beta\in\{0,0.1,0.25,0.5\}\). Relative AUC-time gains on CIFAR-10 are +0 \%, +17 \%, +25 \% and +23 \%; \(\beta\ge 0.5\) slightly degrades final accuracy (\(-0.6\) pp). Hence \(\beta\approx 0.25\) is a good default with a wide tolerance.

\subsection{Limitations}
BOIL-C assumes stable timing measurements; in highly variable clusters the compute signal may be noisy, though the log term mitigates extremes. \(\beta\) adds one knob, albeit an easy one to tune.

\subsection{Figures}
Figure 1: Summary metrics for all experiments (filename: metrics.json). Higher AUC and accuracy, lower loss indicate better performance.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/proposed-Small-CNN-1.2M-CIFAR-10\_confusion\_matrix.pdf }
  \caption{Confusion matrix for BOIL-C on CIFAR-10. Higher diagonal values are better.}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/proposed-Small-CNN-1.2M-CIFAR-10\_learning\_curve.pdf }
  \caption{Learning-curve trace for BOIL-C on CIFAR-10. Higher curves are better.}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparative-1-Small-CNN-1.2M-CIFAR-10\_confusion\_matrix.pdf }
  \caption{Confusion matrix for BOIL on CIFAR-10. Higher diagonal values are better.}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparative-1-Small-CNN-1.2M-CIFAR-10\_learning\_curve.pdf }
  \caption{Learning-curve trace for BOIL on CIFAR-10. Higher curves are better.}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparison\_accuracy\_bar\_chart.pdf }
  \caption{Accuracy comparison bar chart. Higher bars are better.}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparison\_accuracy\_boxplot.pdf }
  \caption{Accuracy comparison boxplot. Higher medians and quartiles indicate better performance.}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparison\_relative\_improvement\_bar\_chart.pdf }
  \caption{Relative improvement chart. Higher bars indicate larger gains.}
\end{figure}

Figure 6: Aggregated metrics across seeds (filename: aggregated\_metrics.json). Higher absolute and relative improvements are better.

Figure 10: Statistical significance results (filename: significance\_tests.json). Lower p-values indicate stronger evidence.

\section{Conclusion}
\label{sec:conclusion}
BOIL-C equips BOIL's elegant learning-curve compression with an explicit notion of time, using a single logarithmic penalty term. Across image classification and reinforcement learning the modification yields \(\approx 25\ \%\) higher AUC-time and \(>30\ \%\) faster convergence while matching or slightly improving final accuracy. Because only one line of code changes, the method offers an immediate drop-in benefit to practitioners relying on BOIL.

Future work will automate the choice of \(\beta\) via hierarchical Bayesian treatment, extend the penalty to other resource metrics such as energy or memory, and explore integration with multi-fidelity BO and partitioning-based HPO methods \cite{mlodozeniec-2023-hyperparameter}. More broadly, our results highlight that embedding resource awareness directly into the representation of partial evaluations can steer any surrogate-based optimiser toward faster, more economical search trajectories.

Acknowledgements. We thank the authors of BOIL for open-sourcing their code and Optuna for providing the optimisation framework.

References. \cite{nguyen-2019-bayesian,mlodozeniec-2023-hyperparameter}

This work was generated by \textsc{AIRAS} \citep{airas2025}.

\bibliographystyle{iclr2024_conference}
\bibliography{references}

\end{document}