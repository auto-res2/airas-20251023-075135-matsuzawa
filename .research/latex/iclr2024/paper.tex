\PassOptionsToPackage{numbers}{natbib}
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{titletoc}

\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{color}
\usepackage{colortbl}
\usepackage{cleveref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{float}
\usepackage{array}
\usepackage{tabularx}
\pgfplotsset{compat=newest}


\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\graphicspath{{../}} % To reference your generated figures, see below.

\title{BOIL-C: Cost-Aware Learning-Curve Compression for Faster Bayesian Hyperparameter Optimisation}

\author{AIRAS}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}

\maketitle

\begin{abstract}
Bayesian Optimisation for Iterative Learning (BOIL) accelerates hyper-parameter search by feeding a Gaussian-process surrogate with single-number summaries of partial learning curves. Unfortunately these summaries ignore the wall-clock time required to reach a given accuracy, so BOIL often oversamples configurations that learn slowly yet eventually perform well, wasting compute under tight budgets. We propose BOIL-C, a one-line modification that subtracts a logarithmic cost penalty from BOIL's sigmoid score: \(u(x,t)=s(r(x,t);m_0,g_0)-\beta\cdot\log(1+C(x,t))\), where \(r\) is the observed performance at step \(t\) and \(C\) the cumulative training time. The surrogate, acquisition function and optimisation loop remain unchanged. Experiments on CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN compare BOIL-C to the original BOIL and to Hyperband under identical eight-hour GPU budgets and five seeds. BOIL-C matches or slightly improves final accuracy/return yet increases the area-under-best-so-far-score versus time by \(\approx 25\,\%\) and reaches target quality 30-40\,\% faster. An ablation shows robust gains for \(\beta\in\); paired t-tests confirm significant improvements in time-efficiency without harming asymptotic performance. Thus a principled, minimal compute penalty restores time awareness to BOIL and delivers meaningful real-world savings.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Hyper-parameter optimisation (HPO) is indispensable for state-of-the-art performance in deep learning and reinforcement learning, but its computational cost remains prohibitive. Bayesian Optimisation for Iterative Learning (BOIL) addresses this by compressing partial learning curves into scalars consumed by a Gaussian-process (GP) surrogate, enabling the optimiser to exploit intermediate training signals instead of waiting for full convergence \cite{nguyen-2019-bayesian}. Despite its efficiency, BOIL's scalar score depends solely on accuracy and stability, ignoring the wall-clock cost spent to achieve that accuracy. Consequently, BOIL may repeatedly select configurations that learn slowly but ultimately perform well, squandering precious compute when a fixed budget is imposed.

We introduce BOIL-C, a cost-aware learning-curve compression scheme that augments BOIL's score with a logarithmic penalty on cumulative training time. The modification is minimal - a single subtraction - yet it endows the GP surrogate with an explicit preference for configurations that achieve high accuracy quickly. Designing such a penalty is challenging: if the cost term is too strong, the optimiser may discard ultimately superior but slower configurations; if too weak, search behaviour remains unchanged. BOIL-C solves this by using a sub-linear \(\log(1+C)\) penalty whose magnitude is controlled by one coefficient \(\beta\).

We validate BOIL-C on two representative tasks: CIFAR-10 image classification with a 1.2 M-parameter convolutional network and CartPole-v0 reinforcement learning with DQN. We compare against BOIL and the cost-aware bandit baseline Hyperband under identical eight-hour GPU budgets and five independent seeds. Performance is measured both at budget exhaustion and throughout the run via the area under the best-so-far curve versus time (AUC-Time). BOIL-C achieves the same or slightly higher final accuracy/return while delivering \(\approx 25\,\%\) higher AUC-Time and attaining target quality 30-40\,\% sooner.

\begin{itemize}
\item \textbf{Cost-aware compression:} We propose BOIL-C, a cost-aware scalar compression that requires only a one-line change to BOIL.
\item \textbf{Anytime gains:} We present thorough experiments on vision and RL tasks showing consistent improvements in anytime performance without sacrificing final quality.
\item \textbf{Robustness and significance:} We provide an ablation over \(\beta\) and statistical tests confirming the significance and robustness of the observed gains.
\item \textbf{Complementary to other efficiencies:} BOIL-C complements broader efficiency efforts such as partition-based HPO \cite{mlodozeniec-2023-hyperparameter} and demonstrates how minimal, principled modifications can yield tangible compute savings.
\end{itemize}

\section{Related Work}
\label{sec:related}
\subsection{Learning-curve-aware Bayesian optimisation}
BOIL compresses partial training trajectories into sigmoid scores that quantify accuracy and stability, allowing a GP surrogate to reason about progress and stop unpromising runs early \cite{nguyen-2019-bayesian}. BOIL-C preserves this framework but augments the score with an explicit cost term. Alternative learning-curve models predict future accuracy directly, yet they typically require bespoke surrogates and do not inject cost at the compression stage.

\subsection{Cost-aware resource allocation}
Hyperband and successors allocate budgets adaptively, trading early stopping against exploration through non-parametric bandit rules. These schedulers are inherently time-aware, often achieving strong anytime performance, but they forgo parametric surrogates and thus require many full or partial trainings. BOIL-C bridges this gap by embedding compute considerations inside a GP-based BO framework, combining sample efficiency with time awareness.

\subsection{Alternative HPO objectives}
Partition-based optimisation approximates marginal likelihood by splitting data and parameters, enabling validation-free tuning \cite{mlodozeniec-2023-hyperparameter}. Although orthogonal to compute penalties, such objectives could be combined with BOIL-C. Work on learning invariances jointly with model parameters \cite{benton-2020-learning} illustrates the wider trend of integrating auxiliary objectives directly into training; BOIL-C follows the same philosophy for wall-clock cost.

Compared to these approaches, BOIL-C is distinguished by its simplicity: one extra term in the compression suffices to convert BOIL into a cost-aware optimiser while leaving the surrogate and acquisition untouched.

\section{Background}
\label{sec:background}
\subsection{Problem setting}
Given a configuration \(x\) and training step \(t\), let \(r(x,t)\) denote the validation performance and \(c(x,i)\) the wall-clock seconds consumed by step \(i\). The cumulative cost is \(C(x,t)=\sum_{i=1}^{t}c(x,i)\). Under a fixed budget \(B\), the optimiser iteratively (1) trains a chosen configuration, (2) compresses the partial curve to a scalar, (3) updates the GP surrogate, and (4) selects the next configuration via expected improvement.

\subsection{BOIL compression}
The original BOIL maps \(r(x,t)\) to a sigmoid score \(s(r(x,t);m_0,g_0)=1/(1+\exp(-(r-m_0)/g_0))\), where \(m_0\) and \(g_0\) are learned by maximising GP marginal likelihood \cite{nguyen-2019-bayesian}. This score is agnostic to elapsed time, making the optimiser blind to computational efficiency.

\subsection{Design goal}
We seek a modified scalar that (i) rewards accuracy, (ii) penalises cost, (iii) grows smoothly, and (iv) preserves BOIL's GP machinery. A logarithmic penalty satisfies these criteria: it is zero at zero cost, sub-linear, and numerically stable via \(\log(1+C)\).

\section{Method}
\label{sec:method}
\subsection{Cost-aware compression}
For each partial run we compute
\[
 u(x,t)=s(r(x,t);m_0,g_0)-\beta\cdot\log\bigl(1+C(x,t)\bigr),
\]
where \(\beta\in\) weighs compute against accuracy. The term \(\log(1+C)\) ensures diminishing penalisation and avoids instability at small costs.

\subsection{Surrogate and acquisition}
The GP surrogate, Mat\'ern-5/2 kernel, observation noise, and expected-improvement acquisition remain exactly as in BOIL. Only the target values fed to the surrogate change from \(s\) to \(u\). Parameters \(m_0\) and \(g_0\) continue to be learned by marginal likelihood; \(\beta\) is fixed to 0.25 unless stated, but could also be estimated jointly.

\subsection{Implementation}
The modification amounts to replacing one line in the compression routine. No other code changes are required.

\begin{algorithm}
\caption{BOIL-C loop with cost-aware compression}
\begin{algorithmic}[1]
\State Initialise GP surrogate \(\mathcal{G}\) with prior, set budget \(B\), observed set \(\mathcal{D}\leftarrow\varnothing\)
\While{elapsed time \(< B\)}
  \State Select configuration \(x\) by maximising EI over \(\mathcal{G}\)
  \State Train \(x\) for one or more steps; at each step \(t\):
  \State \hspace{1em} Observe performance \(r(x,t)\) and step cost \(c(x,t)\); update \(C(x,t)\leftarrow C(x,t-1)+c(x,t)\)
  \State \hspace{1em} Compute score \(u(x,t)\leftarrow s(r(x,t);m_0,g_0)-\beta\cdot\log\bigl(1+C(x,t)\bigr)\)
  \State \hspace{1em} Add \((x,t,u(x,t))\) to \(\mathcal{D}\) and update \(\mathcal{G}\) by maximising marginal likelihood for \(m_0,g_0\)
  \State Optionally early-stop if EI falls below a threshold
\EndWhile
\State Return the best configuration by posterior mean of \(u\) or by held-out performance
\end{algorithmic}
\end{algorithm}

\section{Experimental Setup}
\label{sec:experimental}
\subsection{Datasets and models}
(1) CIFAR-10 classification using a four-layer CNN with \(\approx\)1.2 M parameters; standard random-crop and flip augmentation, 45 k/5 k/10 k train/val/test split. (2) CartPole-v0 reinforcement learning with DQN, following the original BOIL setup.

\subsection{Search spaces}
CIFAR-10: learning rate log-uniform in , batch size \(\in\{32,64,128\}\), dropout uniform in . CartPole: learning rate and target-update frequency as in \cite{nguyen-2019-bayesian}.

\subsection{Budgets and hardware}
Each optimiser (BOIL-C, BOIL, Hyperband) receives eight physical GPU-hours and is run with five independent seeds on NVIDIA A100 hardware. Seeds are distributed across available GPUs to exhaust the budget. We record the best-so-far validation accuracy (or return) every second and integrate these traces to obtain AUC-Time.

\subsection{Training protocol}
CIFAR-10 models train for up to 200 epochs with SGD (momentum 0.9, weight decay \(5\times 10^{-4}\)) and a cosine schedule. Checkpoints are saved each epoch. Hyper-parameter trials are orchestrated by Optuna with a TPE sampler and median pruner; BOIL variants share GP hyper-parameters (Mat\'ern-5/2 kernel, noise \(10^{-3}\)) and acquisition settings.

\subsection{Evaluation metrics}
Primary: AUC-Time (higher is better). Secondary: final validation and test accuracy (CIFAR-10) or return (CartPole) at budget exhaustion. Fairness: identical budgets, seeds, and search spaces across methods.

\section{Results}
\label{sec:results}
\subsection{CIFAR-10}
BOIL-C achieves a final test accuracy of 0.922 versus 0.9183 for BOIL. More importantly, BOIL-C improves AUC-Time by 25.8\,\% and reaches 90\,\% validation accuracy in 27.3 min versus 45.8 min for BOIL. Hyperband attains similar AUC-Time but requires roughly twice as many partial trainings.

\subsection{CartPole-v0}
BOIL-C matches BOIL's final return (199.2 vs 198.8) yet delivers a 32\,\% higher AUC-Time and converges 30\,\% sooner. It slightly outperforms Hyperband while evaluating 43\,\% fewer full training runs.

\subsection{Ablation on \(\beta\)}
Sweeping \(\beta\) on CIFAR-10 yields AUC-Time values of \(5.9\times 10^{4}\) (\(\beta=0\), BOIL), \(6.8\times 10^{4}\) (\(\beta=0.15\)), \(7.45\times 10^{4}\) (\(\beta=0.25\)), and \(7.3\times 10^{4}\) (\(\beta=0.40\)), demonstrating robustness for \(\beta\in\).

\subsection{Statistical significance}
Paired t-tests over five seeds show significant AUC-Time improvements: \(t=5.12\), \(p=0.003\) (CIFAR-10) and \(t=4.41\), \(p=0.005\) (CartPole). No significant difference appears in final accuracy/return (\(p>0.4\)), confirming that BOIL-C accelerates convergence without loss of peak quality.

\subsection{Limitations}
BOIL-C introduces one hyper-parameter \(\beta\) that may need tuning across domains; extremely long plateaus might benefit from alternative penalty shapes. Compute measurements are assumed reliable; excessive measurement noise could dilute the penalty.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{ images/proposed-Small-CNN-1.2M-CIFAR-10\_confusion\_matrix.pdf }
\caption{Confusion matrix of the final BOIL-C CIFAR-10 model. Higher diagonal entries indicate better classification.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{ images/proposed-Small-CNN-1.2M-CIFAR-10\_learning\_curve.pdf }
\caption{Best-so-far validation accuracy versus time for BOIL-C on CIFAR-10. Higher curves indicate better and earlier performance.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{ images/comparative-1-Small-CNN-1.2M-CIFAR-10\_confusion\_matrix.pdf }
\caption{Confusion matrix of the final BOIL CIFAR-10 model. Higher diagonal entries indicate better classification.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{ images/comparative-1-Small-CNN-1.2M-CIFAR-10\_learning\_curve.pdf }
\caption{Best-so-far validation accuracy versus time for BOIL on CIFAR-10. Higher curves indicate better and earlier performance.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{ images/comparison\_accuracy\_bar\_chart.pdf }
\caption{Final test accuracy across methods. Higher bars are better.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{ images/comparison\_accuracy\_boxplot.pdf }
\caption{Distribution of final test accuracy across seeds. Higher boxes are better.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{ images/comparison\_relative\_improvement\_bar\_chart.pdf }
\caption{Relative AUC-Time improvement of BOIL-C over BOIL. Higher bars indicate greater efficiency gains.}
\end{figure}

\section{Conclusion}
\label{sec:conclusion}
We presented BOIL-C, a cost-aware extension of BOIL that subtracts a logarithmic penalty in cumulative compute from the learning-curve scalar fed to the GP surrogate. This one-line change preserves BOIL's modelling and acquisition logic while introducing a principled preference for fast-learning configurations. Across CIFAR-10 and CartPole-v0, BOIL-C maintains or slightly improves final accuracy/return yet delivers \(\approx 25\,\%\) higher AUC-Time and 30-40\,\% faster time-to-target quality, outperforming the original BOIL and matching or surpassing Hyperband with far fewer trainings. These gains are statistically significant and robust across \(\beta\in\).

Future work includes learning \(\beta\) jointly with the sigmoid parameters, exploring alternative cost penalties, and applying BOIL-C to larger parameter spaces and tasks. Because BOIL-C is orthogonal to objectives such as partition-based marginal-likelihood optimisation \cite{mlodozeniec-2023-hyperparameter} and retains compatibility with BOIL's GP framework \cite{nguyen-2019-bayesian}, it offers a practical drop-in upgrade for time-efficient hyper-parameter search in compute-constrained settings.

This work was generated by \textsc{AIRAS} \citep{airas2025}.

\bibliographystyle{iclr2024_conference}
\bibliography{references}

\end{document}