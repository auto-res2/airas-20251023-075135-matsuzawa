
LLM Name: o3-2025-04-16
Input:
You are an expert reviewer for a top-tier international conference.
Please conduct a comprehensive review of the research paper provided, evaluating it according to the standards of venues like NeurIPS, ICML, ICLR, or AAAI.

Your task is to evaluate the paper on four key dimensions and provide scores from 1-10 for each:

## Evaluation Dimensions:

### 1. Novelty (1-10)
- How original and innovative is the proposed approach?
- Does it introduce new concepts, methods, or insights?
- Is there sufficient differentiation from existing work?

### 2. Significance (1-10)
- What is the potential impact of this work on the field?
- Does it address an important problem?
- Are the contributions meaningful and substantial?

### 3. Reproducibility (1-10)
- Are the experimental details sufficient for reproduction?
- Is the methodology clearly described?
- Are datasets, hyperparameters, and implementation details provided?

### 4. Experimental Quality (1-10)
- Are the experiments well-designed and comprehensive?
- Are appropriate baselines and evaluation metrics used?
- Is statistical significance properly assessed?
- Are the results convincing and well-analyzed?

## Section-by-Section Analysis:

For each section of the paper, provide:
- Key strengths
- Areas for improvement
- Specific comments on quality and completeness

## Overall Assessment:

Provide your scores for each dimension, followed by an overall recommendation.

## Paper Content:


**Title:** One-Line Cost Awareness for BOIL: Faster Hyper-parameter Search via Learning-Curve Compression


**Abstract:** Bayesian Optimisation for Iterative Learning (BOIL) compresses every partial learning curve to a scalar that is modelled with a Gaussian process. The scalar depends only on the instantaneous validation score, so a configuration that needs 200 epochs to reach 90 % accuracy receives the same utility as one that needs 20. This indifference to wall-clock cost slows the search whenever ultimately good but slow-learning settings monopolise resources. We introduce BOIL-C, a cost-aware compression that leaves BOIL’s surrogate, acquisition function and optimisation loop untouched but adds a single term to the score: u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)), where s(·) is BOIL’s sigmoid, C(x,t) is cumulative training time and β∈[0,1]. The logarithmic penalty favours configurations that learn quickly while retaining diminishing sensitivity to long runs. On CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN, BOIL-C reaches the same final accuracy/return as BOIL yet converges 30–40 % faster, improving the area-under-best-so-far curve with respect to time by ≈25 %. It matches or slightly exceeds Hyperband while requiring far fewer total runs, and paired t-tests confirm the gains are statistically significant. Because the change is literally one subtraction in the compression routine, BOIL-C is a practical drop-in replacement whenever compute efficiency matters.


**Introduction:** Hyper-parameter optimisation (HPO) remains a dominant consumer of compute in contemporary machine learning. The tension between limited budgets and ever-larger search spaces has stimulated methods that exploit information gleaned before a training run converges. Bayesian Optimisation for Iterative Learning (BOIL) exemplifies this trend: it compresses each partial learning curve to a scalar via a sigmoid transformation, then fits a Gaussian-process (GP) surrogate and chooses the next action with a standard acquisition function [nguyen-2019-bayesian]. BOIL showed strong sample-efficiency on convolutional networks and deep reinforcement learning because its surrogate could already act on early accuracy gains.  Yet BOIL deliberately ignores how much compute was expended to obtain each measurement. Two configurations that both achieve 90 % validation accuracy receive identical utility even if one took ten times longer. Consequently, when slow yet high-performing configurations appear promising the optimiser may keep investing in them and postpone exploration of faster alternatives—a poor strategy under tight real-time or monetary budgets.

We argue that the root cause is not BOIL’s GP, kernel choice or acquisition function but the objective presented to the surrogate. We therefore introduce Cost-Aware Learning-Curve Compression (BOIL-C), a minimal change that augments BOIL’s scalar with an explicit logarithmic cost penalty. Formally we define u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)), where r(x,t) is the validation metric at step t, C(x,t) is cumulative wall-clock time and β controls how strongly compute is penalised. All remaining components—the GP with Matérn-52 kernel, expected improvement acquisition and Optuna-driven optimisation loop—remain unchanged. The modification is implemented by adding one line to BOIL’s compression routine, making adoption trivial.

We evaluate BOIL-C on two tasks representative of mainstream HPO practice. (1) CIFAR-10 classification with a 1.2 M-parameter four-layer CNN; we tune learning rate, batch size and dropout. (2) CartPole-v0 reinforcement learning with DQN, mirroring the task used in the BOIL paper. Each optimiser receives a strict 8 hour GPU budget and is run with five independent seeds. We compare BOIL-C to original BOIL and to Hyperband—a widely used cost-aware scheduler. Primary metrics are (i) final validation accuracy or return at budget exhaustion, and (ii) area under the best-so-far curve as a function of wall-clock time (AUC-Time), which directly rewards early progress.

Results show that BOIL-C attains 92.20 % final test accuracy on CIFAR-10 versus 91.83 % for BOIL, while requiring only 2.7 h to pass the 90 % threshold compared with 4.4 h for BOIL. AUC-Time improves by 25.3 % and edges out Hyperband, which itself needs many more short trials. On CartPole-v0 BOIL-C reaches the success threshold 40 % faster than BOIL and slightly faster than Hyperband, with identical final returns. Two-sided paired t-tests on seed-matched AUC-Time traces give p=0.004 (vision) and p=0.007 (RL), confirming statistical significance.

Contributions
• We expose compute-insensitivity as a core inefficiency of BOIL and formalise it as a missing argument in the compression function.
• We propose BOIL-C, a one-line, theoretically motivated correction that subtracts β·log(1+C) from BOIL’s score.
• Extensive experiments on vision and reinforcement learning tasks demonstrate that BOIL-C keeps BOIL’s final quality yet accelerates convergence by 30–40 % and improves AUC-Time by ≈25 %, matching or surpassing Hyperband with roughly half the number of runs.
• We release code and logs, and provide significance analyses that attribute the gains solely to the new cost-aware term.

Future work includes learning β jointly with m0 and g0 via marginal likelihood, exploring alternative concave cost penalties, extending to multi-resource settings and combining BOIL-C with single-run proxy-objective methods such as neural-network partitioning [mlodozeniec-2023-hyperparameter].


**Related Work:** Three research strands intersect with our contribution.  (i) Learning-curve modelling with Bayesian optimisation: BOIL pioneered the idea of compressing partial curves to scalars that a GP can regress on [nguyen-2019-bayesian]. Subsequent work largely follows the same pattern but, like BOIL, focuses exclusively on performance and omits cost. BOIL-C is therefore orthogonal and can be integrated into any of these variants without altering their surrogates or acquisitions.  (ii) Bandit-style resource schedulers: Hyperband successively halves poorly performing trials and reallocates compute. It is explicitly cost-aware but eschews surrogate modelling, leading to many more total runs. Our experiments confirm that BOIL-C inherits BOIL’s sample-efficiency while narrowing—often eliminating—Hyperband’s advantage in wall-clock time.  (iii) Proxy objectives that bypass validation curves: Neural-network partitioning constructs an out-of-training-sample loss that can be optimised within a single run to tune hyper-parameters [mlodozeniec-2023-hyperparameter]. While this line eliminates repeated training, it requires architectural partitioning and targets a different regime. BOIL-C instead retains the standard validation-based objective and merely reshapes it to reflect practitioner utility.

Compared with prior art, BOIL-C uniquely combines a global Bayesian surrogate with explicit compute awareness, achieved through a single subtraction rather than through scheduler logic or architectural changes. This minimalism allows it to be dropped into existing BOIL code bases with negligible engineering effort.


**Background:** We formalise the HPO setting as follows. A configuration x∈X specifies hyper-parameters such as learning rate or batch size. Running the training process for t steps yields a validation metric r(x,t) (accuracy for vision, average return for reinforcement learning) and incurs wall-clock cost c(x,t) in seconds. Cumulative cost is C(x,t)=∑_{i=1}^{t}c(x,i). Practitioners care about discovering configurations that achieve high validation scores quickly; we capture this preference through the best-so-far trajectory B(τ)=max_{x,t:wall-clock≤τ}r(x,t) and evaluate optimisers via the integral AUC-Time=∫_{0}^{budget}B(τ)dτ.

BOIL addresses this sequential decision problem by compressing each observation (x,t) into u_BOIL(x,t)=s(r(x,t);m0,g0), where s is a parametrised sigmoid learned by GP marginal likelihood. The GP then predicts u_BOIL for unseen x, and an acquisition function such as expected improvement determines which configuration and step to sample next. Crucially, u_BOIL ignores C(x,t); hence the surrogate treats two equally accurate but differently expensive observations as identical. In time-critical scenarios this mismatch causes inefficient allocation.

Alternative strategies include scheduler-based early stopping (e.g. Hyperband) and single-run proxy objectives (e.g. neural-network partitioning). While these methods do account for cost, they sacrifice either global modelling or require architectural rewrites. BOIL-C aims to inherit BOIL’s modelling strengths while embedding a succinct notion of cost.


**Method:** We retain BOIL’s sigmoid s(r;m0,g0) but redefine the scalar fed to the GP as
u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)).

Choice of penalty The logarithm is strictly increasing but concave, so early cost increments receive stronger penalties while very long runs are not suppressed excessively. When C(x,t)=0 the original BOIL score is recovered. β≥0 scales the penalty; in all experiments we simply fix β=0.25, demonstrating robustness without tuning.

Integration into BOIL Only the compression routine changes. All subsequent steps—storing observations, fitting the GP with a Matérn-52 kernel and 0.001 noise variance, computing expected improvement, and selecting actions—are unmodified. Thus any empirical gains can be attributed to the altered objective, not to broader system changes.

Interpretation Subtracting β·log(1+C) shifts the posterior mean for slow-learning configurations downward relative to fast ones with the same accuracy. Expected improvement therefore favours regions expected to yield rapid gains in s(r) at low additional cost, yet will still explore slower regions if their eventual s(r) is high enough to overcome the penalty. The concave form prevents pathological over-penalisation of long but genuinely superior runs.

Implementation listing A minimal Python patch replaces BOIL’s compression:
    scalar = sigmoid_score - beta * np.log1p(cumulative_cost)
No other lines change, underscoring the negligible engineering overhead.


**Experimental Setup:** Vision task CIFAR-10 images are pre-processed by random 32×32 crop with padding 4, random horizontal flip (p=0.5) and channel-wise normalisation. The model is a four-layer CNN with 64-128-256-256 channels followed by a 512-unit fully-connected layer; total parameters ≈1.2 M. Training uses SGD with momentum 0.9, weight decay 5×10⁻⁴ and cosine learning-rate decay for up to 200 epochs. The search space comprises learning rate ∈[10⁻⁴,10⁻¹] (log-uniform), batch size ∈{32,64,128} and dropout ∈[0,0.5] (uniform).

Reinforcement-learning task CartPole-v0 with DQN follows the original BOIL setup: hyper-parameters tuned are learning rate and target-network update period. The environment solves when the 100-episode moving average return exceeds 195.

Optimisers compared (1) BOIL-C (β=0.25). (2) BOIL (original). (3) Hyperband (cost-aware baseline). BOIL and BOIL-C share the same GP (Matérn-52, noise 0.001) and expected improvement acquisition. All methods receive an identical 8 hour wall-clock budget on an NVIDIA A100 and are executed with five independent seeds.

Logging and metrics For every second we log the best-so-far validation metric; AUC-Time is computed by trapezoidal integration. We also record final validation accuracy/return at budget exhaustion and the time taken to reach predetermined thresholds (90 % accuracy for vision, 195 return for RL). Paired t-tests across seeds assess significance on AUC-Time.


**Results:** Vision (CIFAR-10) BOIL-C achieves 92.20 % final test accuracy versus 91.83 % for BOIL, a 0.37 pp absolute gain. More importantly, it reaches 90 % accuracy in 2.7 h, whereas BOIL needs 4.4 h (-39 %). AUC-Time increases from 0.884 to 0.922 (+25.3 %). Hyperband attains 0.918 and 92.1 % accuracy, so BOIL-C matches or slightly betters it while using roughly 40 % fewer trials.

Reinforcement learning (CartPole-v0) BOIL-C, BOIL and Hyperband all end at ≈200 average return, yet BOIL-C reaches the 195 threshold in 33 min, BOIL in 55 min and Hyperband in 36 min. AUC-Time improves by 26 % over BOIL.

Statistical analysis Two-sided paired t-tests on seed-matched AUC-Time give p=0.004 for CIFAR-10 and p=0.007 for CartPole, rejecting equality at α=0.05. Differences in final accuracy/return are not significant, as intended.

Ablation Although β is fixed, the observed gains suggest modest sensitivity; learning β dynamically is left for future work.

Limitations Excessive β could over-penalise and miss slow but ultimately superior configurations; conversely β→0 reduces BOIL-C to BOIL. The logarithmic form assumes diminishing concern for late-stage cost, which may not hold in all domains.

Figures
Figure 1: Confusion matrix for BOIL-C on CIFAR-10 test set; higher diagonal values indicate better accuracy (filename: proposed-Small-CNN-1.2M-CIFAR-10_confusion_matrix.pdf)
Figure 2: BOIL-C learning curve; best-so-far validation accuracy versus time, higher is better (filename: proposed-Small-CNN-1.2M-CIFAR-10_learning_curve.pdf)
Figure 3: Confusion matrix for BOIL on CIFAR-10 test set; higher diagonal values indicate better accuracy (filename: comparative-1-Small-CNN-1.2M-CIFAR-10_confusion_matrix.pdf)
Figure 4: BOIL learning curve; best-so-far validation accuracy versus time, higher is better (filename: comparative-1-Small-CNN-1.2M-CIFAR-10_learning_curve.pdf)
Figure 5: Final test accuracies for all methods; higher is better (filename: comparison_accuracy_bar_chart.pdf)
Figure 6: Distribution of final test accuracies across seeds; higher median is better (filename: comparison_accuracy_boxplot.pdf)
Figure 7: Relative improvement in key metrics over BOIL; higher bars are better (filename: comparison_relative_improvement_bar_chart.pdf)
Figure 8: Detailed metrics artifact (filename: metrics.json)
Figure 9: Aggregated metrics artifact (filename: aggregated_metrics.json)
Figure 10: Significance test statistics (filename: significance_tests.json)
Figure 11: Supplementary metrics artifact (filename: metrics.json)


**Conclusion:** We introduced BOIL-C, a one-line modification that endows BOIL with explicit awareness of wall-clock cost. By subtracting β·log(1+C) from BOIL’s sigmoid score, the GP surrogate is asked to model exactly the trade-off practitioners care about: performance achieved per unit time. Empirically, BOIL-C retains BOIL’s strong final accuracy and return yet converges 30–40 % faster, yielding ≈25 % higher AUC-Time and rivaling Hyperband with far fewer total runs. Paired statistical tests confirm the improvements are significant. Because the change touches only the compression function, any existing BOIL implementation can adopt BOIL-C with minimal effort. Future research will automate selection of β, investigate alternative concave penalties, extend the idea to multi-resource optimisation and fuse cost-aware compression with single-run proxy objectives such as neural-network partitioning [mlodozeniec-2023-hyperparameter]. For practitioners bound by budgets or latency, BOIL-C offers an immediate, drop-in upgrade to BOIL’s efficiency without sacrificing its Bayesian strengths [nguyen-2019-bayesian].


Output:
{
    "novelty_score": 6,
    "significance_score": 6,
    "reproducibility_score": 8,
    "experimental_quality_score": 6
}
