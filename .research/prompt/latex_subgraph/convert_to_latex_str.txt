
LLM Name: gpt-5-2025-08-07
Input:

You are a LaTeX expert.
Your task is to convert each section of a research paper into plain LaTeX **content only**, without including any section titles or metadata.

Below are the paper sections. For each one, convert only the **content** into LaTeX:

---
Section: title

BOIL-C: Cost-Aware Learning-Curve Compression for Faster Hyperparameter Optimisation

---

---
Section: abstract

Bayesian optimisation for iterative learners commonly exploits partially observed learning curves by compressing them into scalar utilities for a surrogate model. In the original BOIL framework this compression ignores wall-clock cost, so runs that attain identical accuracy receive identical utility even when one is an order of magnitude slower \cite{nguyen-2019-bayesian}. That bias wastes compute under fixed time budgets. We introduce BOIL-C, a one-line modification that subtracts a logarithmic penalty from the BOIL score: u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)), where s(·) is BOIL’s sigmoid score, C(x,t) the cumulative observed training cost, and β∈ a small weight. The surrogate, acquisition function and optimisation loop remain untouched, so BOIL-C is a drop-in change that favours hyper-parameters which reach good accuracy quickly. On CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN we compare BOIL-C to BOIL and (for RL) to Hyperband. With an 8 GPU-hour budget and five seeds BOIL-C matches or slightly improves final accuracy yet raises the area-under-best-so-far-versus-time by ≈25 % on CIFAR-10, cuts median time-to-90 % accuracy by 31 %, and reaches the RL success threshold with 28 % fewer interaction steps than BOIL, on par with Hyperband while evaluating fewer configurations. An ablation over β reveals a broad, easy-to-tune regime. These findings show that a principled, cost-aware scalar yields meaningful time savings without sacrificing model quality.

---

---
Section: introduction

Hyper-parameter optimisation (HPO) for deep learning remains expensive because each evaluation entails running an iterative algorithm—such as SGD or Q-learning—to near convergence. Bayesian optimisation (BO) techniques that exploit partial learning curves relieve this burden by extracting signal early and steering the search accordingly. BOIL compresses every curve prefix into a single scalar reflecting performance and stability, feeds those scalars to a Gaussian-process surrogate, and selects the next configuration via an acquisition function \cite{nguyen-2019-bayesian}.

A blind spot of BOIL is cost agnosticism: two runs that ultimately reach the same accuracy receive the same utility regardless of how long they took. In practice this biases BO toward slow but eventually strong configurations, delaying progress under wall-clock constraints. We therefore ask: can BOIL’s compression be made cost-aware with minimal disruption to the rest of the pipeline?

The challenge is twofold. First, any penalty must be generic—applicable across tasks and metrics—and must preserve the desirable monotonicity of BOIL’s score with respect to performance. Second, the modification should neither destabilise the surrogate nor require re-engineering downstream components.

We propose BOIL-C, which augments BOIL’s score with a logarithmic cost penalty. For configuration x after t steps we define
u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)),
where C(x,t) is cumulative wall-clock seconds and β controls the trade-off. The log ensures diminishing penalties, encouraging rapid progress early without discarding promising but slower curves. Setting β=0 recovers BOIL exactly, hence BOIL-C is a strict generalisation.

We evaluate BOIL-C on two contrasting domains: image classification on CIFAR-10 with a modest CNN and reinforcement learning on CartPole-v0 with DQN. All methods—BOIL-C, BOIL and (for RL) Hyperband—receive identical 8 GPU-hour budgets and are run with five independent seeds. Efficiency is measured by integrating the best-so-far validation metric over wall-clock time (AUC-Time). BOIL-C preserves or slightly betters final performance while substantially improving AUC-Time and reducing time-to-threshold.

Contributions
• A cost-aware learning-curve compression that adds a single logarithmic term to BOIL’s scalar, requiring only one line of code.
• A theoretical justification and practical guidance for choosing β.
• Comprehensive experiments on CIFAR-10 and CartPole-v0 showing ≈25–30 % faster time-to-result without loss of accuracy or return.
• A discussion placing BOIL-C among cost-aware HPO strategies and contrasting it with partition-based objectives \cite{mlodozeniec-2023-hyperparameter}.

Future work includes adaptive β schedules, integration with multi-fidelity schedulers and evaluation on larger-scale tasks.

---

---
Section: related_work

Iterative-learning BO. BOIL is a seminal example of using partial curves within BO \cite{nguyen-2019-bayesian}. Follow-up work has explored hierarchical surrogates and curve extrapolation yet still compresses curves independently of cost. BOIL-C differs by embedding cost directly in the scalar target, leaving the surrogate unchanged.

Cost-aware schedulers. Hyperband and successive-halving allocate resources adaptively based on intermediate results, implicitly trading accuracy against compute. Those methods act at the scheduler level, whereas BOIL-C embeds cost inside the surrogate target, making it orthogonal and in principle combinable with schedulers.

Alternative objectives. Neural network partitioning optimises hyper-parameters via an out-of-sample loss computed from parameter/data shards, bypassing validation data entirely \cite{mlodozeniec-2023-hyperparameter}. While elegant, that objective assumes a single training run and different statistical properties; it is therefore not directly comparable to BO’s iterative evaluation paradigm adopted here.

---

---
Section: background

Problem setting. Let x denote a hyper-parameter configuration and r(x,t) the validation metric after t training steps (epochs for supervised learning, environment interactions for RL). Each step incurs cost c(x,t) seconds, and cumulative cost is C(x,t)=∑_{i≤t}c(x,i). We wish to maximise r subject to a fixed wall-clock budget.

BOIL’s compression. BOIL maps each partial curve to s(r(x,t);m0,g0)=1∕(1+exp(−(r−m0)/g0)), where m0 and g0 are learnt hyper-parameters, and feeds that scalar to a Gaussian-process surrogate. The acquisition function (expected improvement, EI) balances exploration and exploitation when proposing either to extend an existing run or start a new one.

Limitations. Because s depends only on r, the surrogate undervalues fast learners and overvalues slow ones that will eventually perform well, delaying progress when the budget is tight. Addressing this deficiency motivates BOIL-C.

---

---
Section: method

Cost-aware compression. BOIL-C defines the utility
u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)).
The logarithm ensures u remains bounded and yields diminishing penalties: a second of cost early is penalised more than a second late. β may be fixed (0.25 in our experiments) or optimised jointly with m0,g0 by marginal likelihood.

Algorithmic integration. Only Step (utility computation) of BOIL changes. All subsequent steps—GP update, EI maximisation, choice between continuing or starting runs—are identical. The modification is therefore a literal one-line replacement:
scalar = sigmoid_score − β·log1p(cumulative_cost).

Properties.
• Monotonicity in r is preserved for any β≥0; higher accuracy still yields higher utility at equal cost.
• Setting β=0 recovers BOIL exactly.
• Because cost is measured in seconds on homogeneous hardware the penalty is comparable across configurations without further normalisation.

---

---
Section: experimental_setup

Datasets and models. CIFAR-10: 45 k/5 k/10 k train/val/test split. Model: four 3×3 conv layers (64–128–256–256), ReLU, 512-unit fully connected layer, dropout, ≈1.2 M parameters. CartPole-v0: DQN with standard target network and ε-greedy exploration.

Search spaces. CIFAR-10: learning-rate ∈ (log-uniform), batch-size ∈{32,64,128}, dropout ∈. CartPole: learning-rate ∈, target-update ∈{100,200,400,800} steps.

Optimisation budget. Each optimiser (BOIL-C, BOIL, Hyperband) receives 8 physical GPU-hours and is run with five independent random seeds. Single NVIDIA A100 GPUs are assigned per trial; seeds run in parallel to saturate the budget.

Training details. CIFAR-10 uses SGD with momentum 0.9, weight decay 5×10⁻⁴, 200 epochs, cosine LR schedule and batch-size 64 unless overridden by the search space. RL follows the standard DQN recipe; interaction steps rather than episodes define the curve index t.

Logging and metrics. The best-so-far validation metric is recorded each wall-clock second. Integrating that trace yields AUC-Time (higher = better). We also report final validation and test accuracy/return and confusion matrices. Hardware timing overhead is negligible relative to training time.

Baselines. BOIL is implemented exactly as in the authors’ repository. Hyperband uses the same search space and budget on CartPole, providing a strong cost-aware benchmark.

---

---
Section: results

CIFAR-10. Table 1 summarises averaged results over five seeds.
• Final test accuracy: BOIL-C 92.20 %, BOIL 91.83 % (+0.37 pp).
• Final test loss: 0.309 vs 0.332 (lower is better).
• AUC-Time: BOIL-C improves by 24.9 %.
• Median time to 90 % accuracy: 2.8 h vs 4.1 h (−31.7 %).
Figure 1 illustrates the per-second traces; Figure 2 and Figure 4 show confusion matrices. Gains are distributed across classes—for instance, correct class-0 predictions rise from 928→935—confirming no performance trade-off.

CartPole-v0. BOIL-C achieves the success return of 195 in 52 k interaction steps, BOIL in 78 k (−28 %), and Hyperband in 55 k. AUC-Time mirrors these trends (+28 % over BOIL, +2 % over Hyperband). Notably, BOIL-C evaluates ≈30 % fewer configurations than Hyperband yet attains identical speed.

Ablation on β. β∈{0,0.1,0.25,0.5}. AUC-Time gains are +0 %, +17 %, +25 %, −3 % respectively; β=0.5 slightly hurts final accuracy (–0.6 pp). Thus β=0.1-0.3 is a robust operating range.

Fairness. All runs used identical budgets, seeds, search spaces and training pipelines. Surrogate hyper-parameters (kernel, noise) and acquisition (EI) were shared. The sole difference between BOIL and BOIL-C is the cost-aware scalar.

Limitations. BOIL-C presumes reasonably stable timing; heterogeneous or cloud settings may require normalisation. Extremely large β can over-penalise compute-heavy but ultimately superior configurations.

---

---
Section: conclusion

BOIL-C demonstrates that incorporating compute cost directly into learning-curve compression is a powerful yet simple means to accelerate Bayesian hyper-parameter optimisation. A single logarithmic penalty term steers BO toward configurations that learn quickly, yielding ≈25–30 % faster time-to-result on both supervised and reinforcement-learning benchmarks while matching or slightly improving final performance. Because the surrogate, acquisition and scheduler remain untouched, BOIL-C can be adopted in existing BOIL pipelines with minimal effort. Future directions include adaptive β schedules, integration with asynchronous multi-fidelity frameworks and evaluation on larger-scale tasks such as ImageNet or continuous-control RL environments.

References: BOIL \cite{nguyen-2019-bayesian}; neural-network partitioning for HPO \cite{mlodozeniec-2023-hyperparameter}.

---


## LaTeX Formatting Rules:
- Use \subsection{...} for any subsections within this section.
    - Subsection titles should be distinct from the section name;
    - Do not use '\subsection{  }', or other slight variations. Use more descriptive and unique titles.
    - Avoid excessive subdivision. If a subsection is brief or overlaps significantly with another, consider merging them for clarity and flow.

- For listing contributions, use the LaTeX \begin{itemize}...\end{itemize} format.
    - Each item should start with a short title in \textbf{...} format.
    - Avoid using -, *, or other Markdown bullet styles.

- When including tables, use the `tabularx` environment with `\textwidth` as the target width.
    - At least one column must use the `X` type to enable automatic width adjustment and line breaking.
    - Include `\hline` at the top, after the header, and at the bottom. Avoid vertical lines unless necessary.
    - To left-align content in `X` columns, define `
ewcolumntype{Y}{>{
aggedrightrraybackslash}X}` using the `array` package.

- When writing pseudocode, use the `algorithm` and `algorithmicx` LaTeX environments.
    - Only include pseudocode in the `Method` section. Pseudocode is not allowed in any other sections.
    - Prefer the `\begin{algorithmic}` environment using **lowercase commands** such as `\State`, `\For`, and `\If`, to ensure compatibility and clean formatting.
    - Pseudocode must represent actual algorithms or procedures with clear logic. Do not use pseudocode to simply rephrase narrative descriptions or repeat what has already been explained in text.
        - Good Example:
        ```latex
        \State Compute transformed tokens: \(	ilde{T} \leftarrow W\,T\)
        \State Update: \(T_{new} \leftarrow 	ilde{T} + \mu\,T_{prev}\)
        ```
- Figures and images are ONLY allowed in the "Results" section.
    - Use LaTeX float option `[H]` to force placement.

- All figures must be inserted using the following LaTeX format, using a `width` that reflects the filename:
    ```latex
    \includegraphics[width=\linewidth]{ images/filename.pdf }
    ```
    The `<appropriate-width>` must be selected based on the filename suffix:
    - If the filename ends with _pair1.pdf or _pair2.pdf, use 0.48\linewidth as the width of each subfigure environment and place the figures side by side using `subcaption` package.
    - Otherwise (default), use 0.7\linewidth

- **Escaping special characters**:
    - LaTeX special characters (`#`, `$`, `%`, `&`, `~`, `_`, `^`, `{`, `}`, `\`) must be escaped with a leading backslash when they appear in plain text (e.g., `data\_set`, `C\&C`).
    - Underscores **must always be escaped** (`\_`) outside math mode, even in filenames (e.g., memory\_profiler), code-style words, itemize lists, or citation contexts.

- Always use ASCII hyphens (`-`) instead of en-dashes (`–`) or em-dashes (`—`) to avoid spacing issues in hyphenated terms.
- Do not include any of these higher-level commands such as \documentclass{...}, \begin{document}, and \end{document}.
    - Additionally, avoid including section-specific commands such as \begin{abstract}, \section{  }, or any other similar environment definitions.
- Do not modify citation placeholders:
    - Citation placeholders appear in the format [citation_key], where citation_key contains underscores, numbers, and text (e.g., [vaswani_2017_attention], [smith_2023_deep]).
    - You must preserve these placeholders EXACTLY as they appear in the input text.
- If no LaTeX conversion is needed, output the content as-is without status messages like [Unchanged].
Output:
{
    "title": "BOIL-C: Cost-Aware Learning-Curve Compression for Faster Hyperparameter Optimisation",
    "abstract": "Bayesian optimisation for iterative learners commonly exploits partially observed learning curves by compressing them into scalar utilities for a surrogate model. In the original BOIL framework this compression ignores wall-clock cost, so runs that attain identical accuracy receive identical utility even when one is an order of magnitude slower \\cite{nguyen-2019-bayesian}. That bias wastes compute under fixed time budgets. We introduce BOIL-C, a one-line modification that subtracts a logarithmic penalty from the BOIL score: \\(u(x,t) = s(r(x,t); m_0, g_0) - \\beta \\cdot \\log\\bigl(1 + C(x,t)\\bigr)\\), where \\(s(\\cdot)\\) is BOIL's sigmoid score, \\(C(x,t)\\) the cumulative observed training cost, and \\(\\beta\\) is a small weight. The surrogate, acquisition function and optimisation loop remain untouched, so BOIL-C is a drop-in change that favours hyper-parameters which reach good accuracy quickly. On CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN we compare BOIL-C to BOIL and (for RL) to Hyperband. With an 8 GPU-hour budget and five seeds BOIL-C matches or slightly improves final accuracy yet raises the area-under-best-so-far-versus-time by \\(\\approx 25\\%\\) on CIFAR-10, cuts median time-to-90\\% accuracy by \\(31\\%\\), and reaches the RL success threshold with \\(28\\%\\) fewer interaction steps than BOIL, on par with Hyperband while evaluating fewer configurations. An ablation over \\(\\beta\\) reveals a broad, easy-to-tune regime. These findings show that a principled, cost-aware scalar yields meaningful time savings without sacrificing model quality.",
    "introduction": "Hyper-parameter optimisation (HPO) for deep learning remains expensive because each evaluation entails running an iterative algorithm-such as SGD or Q-learning-to near convergence. Bayesian optimisation (BO) techniques that exploit partial learning curves relieve this burden by extracting signal early and steering the search accordingly. BOIL compresses every curve prefix into a single scalar reflecting performance and stability, feeds those scalars to a Gaussian-process surrogate, and selects the next configuration via an acquisition function \\cite{nguyen-2019-bayesian}.\n\nA blind spot of BOIL is cost agnosticism: two runs that ultimately reach the same accuracy receive the same utility regardless of how long they took. In practice this biases BO toward slow but eventually strong configurations, delaying progress under wall-clock constraints. We therefore ask: can BOIL's compression be made cost-aware with minimal disruption to the rest of the pipeline?\n\nThe challenge is twofold. First, any penalty must be generic-applicable across tasks and metrics-and must preserve the desirable monotonicity of BOIL's score with respect to performance. Second, the modification should neither destabilise the surrogate nor require re-engineering downstream components.\n\nWe propose BOIL-C, which augments BOIL's score with a logarithmic cost penalty. For configuration \\(x\\) after \\(t\\) steps we define\n\\[ u(x,t) = s\\bigl(r(x,t); m_0, g_0\\bigr) - \\beta\\,\\log\\bigl(1 + C(x,t)\\bigr), \\]\nwhere \\(C(x,t)\\) is cumulative wall-clock seconds and \\(\\beta\\) controls the trade-off. The log ensures diminishing penalties, encouraging rapid progress early without discarding promising but slower curves. Setting \\(\\beta=0\\) recovers BOIL exactly, hence BOIL-C is a strict generalisation.\n\nWe evaluate BOIL-C on two contrasting domains: image classification on CIFAR-10 with a modest CNN and reinforcement learning on CartPole-v0 with DQN. All methods-BOIL-C, BOIL and (for RL) Hyperband-receive identical 8 GPU-hour budgets and are run with five independent seeds. Efficiency is measured by integrating the best-so-far validation metric over wall-clock time (AUC-Time). BOIL-C preserves or slightly betters final performance while substantially improving AUC-Time and reducing time-to-threshold.\n\n\\subsection{Contributions}\n\\begin{itemize}\n  \\item \\textbf{One-line cost-aware compression:} A cost-aware learning-curve compression that adds a single logarithmic term to BOIL's scalar, requiring only one line of code.\n  \\item \\textbf{Guidance for \\(\\beta\\):} A theoretical justification and practical guidance for choosing \\(\\beta\\).\n  \\item \\textbf{Empirical speedups:} Comprehensive experiments on CIFAR-10 and CartPole-v0 showing \\(\\approx 25\\text{-}30\\%\\) faster time-to-result without loss of accuracy or return.\n  \\item \\textbf{Positioning within HPO:} A discussion placing BOIL-C among cost-aware HPO strategies and contrasting it with partition-based objectives \\cite{mlodozeniec-2023-hyperparameter}.\n\\end{itemize}\n\nFuture work includes adaptive \\(\\beta\\) schedules, integration with multi-fidelity schedulers and evaluation on larger-scale tasks.",
    "related_work": "\\subsection{Iterative-learning Bayesian optimisation}\nBOIL is a seminal example of using partial curves within BO \\cite{nguyen-2019-bayesian}. Follow-up work has explored hierarchical surrogates and curve extrapolation yet still compresses curves independently of cost. BOIL-C differs by embedding cost directly in the scalar target, leaving the surrogate unchanged.\n\n\\subsection{Cost-aware schedulers}\nHyperband and successive-halving allocate resources adaptively based on intermediate results, implicitly trading accuracy against compute. Those methods act at the scheduler level, whereas BOIL-C embeds cost inside the surrogate target, making it orthogonal and in principle combinable with schedulers.\n\n\\subsection{Alternative objectives}\nNeural network partitioning optimises hyper-parameters via an out-of-sample loss computed from parameter/data shards, bypassing validation data entirely \\cite{mlodozeniec-2023-hyperparameter}. While elegant, that objective assumes a single training run and different statistical properties; it is therefore not directly comparable to BO's iterative evaluation paradigm adopted here.",
    "background": "\\subsection{Problem setting}\nLet \\(x\\) denote a hyper-parameter configuration and \\(r(x,t)\\) the validation metric after \\(t\\) training steps (epochs for supervised learning, environment interactions for RL). Each step incurs cost \\(c(x,t)\\) seconds, and cumulative cost is \\(C(x,t) = \\sum_{i\\le t} c(x,i)\\). We wish to maximise \\(r\\) subject to a fixed wall-clock budget.\n\n\\subsection{BOIL's compression}\nBOIL maps each partial curve to \\(s\\bigl(r(x,t); m_0, g_0\\bigr) = \\frac{1}{1 + \\exp\\bigl(- (r - m_0)/g_0\\bigr)}\\), where \\(m_0\\) and \\(g_0\\) are learnt hyper-parameters, and feeds that scalar to a Gaussian-process surrogate. The acquisition function (expected improvement, EI) balances exploration and exploitation when proposing either to extend an existing run or start a new one.\n\n\\subsection{Limitations}\nBecause \\(s\\) depends only on \\(r\\), the surrogate undervalues fast learners and overvalues slow ones that will eventually perform well, delaying progress when the budget is tight. Addressing this deficiency motivates BOIL-C.",
    "method": "\\subsection{Cost-aware compression}\nBOIL-C defines the utility\n\\[ u(x,t) = s\\bigl(r(x,t); m_0, g_0\\bigr) - \\beta\\,\\log\\bigl(1 + C(x,t)\\bigr). \\]\nThe logarithm ensures \\(u\\) remains bounded and yields diminishing penalties: a second of cost early is penalised more than a second late. \\(\\beta\\) may be fixed (0.25 in our experiments) or optimised jointly with \\(m_0, g_0\\) by marginal likelihood.\n\n\\subsection{Algorithmic integration}\nOnly the utility computation step of BOIL changes. All subsequent steps-GP update, EI maximisation, choice between continuing or starting runs-are identical. The modification is therefore a literal one-line replacement:\n\\[ \\texttt{scalar} = \\texttt{sigmoid\\_score} - \\beta\\cdot \\texttt{log1p}(\\texttt{cumulative\\_cost}). \\]\n\n\\subsection{Properties}\n\\begin{itemize}\n  \\item \\textbf{Monotonicity:} Monotonicity in \\(r\\) is preserved for any \\(\\beta\\ge 0\\); higher accuracy still yields higher utility at equal cost.\n  \\item \\textbf{Recoverability:} Setting \\(\\beta=0\\) recovers BOIL exactly.\n  \\item \\textbf{Comparability:} Because cost is measured in seconds on homogeneous hardware the penalty is comparable across configurations without further normalisation.\n\\end{itemize}",
    "experimental_setup": "\\subsection{Datasets and models}\nCIFAR-10: \\(45\\,\\text{k}/5\\,\\text{k}/10\\,\\text{k}\\) train/val/test split. Model: four \\(3\\times 3\\) conv layers (64-128-256-256), ReLU, 512-unit fully connected layer, dropout, \\(\\approx\\)1.2 M parameters. CartPole-v0: DQN with standard target network and \\(\\varepsilon\\)-greedy exploration.\n\n\\subsection{Search spaces}\nCIFAR-10: learning-rate \\(\\in\\) (log-uniform), batch-size \\(\\in\\{32,64,128\\}\\), dropout \\(\\in\\). CartPole: learning-rate \\(\\in\\), target-update \\(\\in\\{100,200,400,800\\}\\) steps.\n\n\\subsection{Optimisation budget}\nEach optimiser (BOIL-C, BOIL, Hyperband) receives 8 physical GPU-hours and is run with five independent random seeds. Single NVIDIA A100 GPUs are assigned per trial; seeds run in parallel to saturate the budget.\n\n\\subsection{Training details}\nCIFAR-10 uses SGD with momentum 0.9, weight decay \\(5\\times 10^{-4}\\), 200 epochs, cosine LR schedule and batch-size 64 unless overridden by the search space. RL follows the standard DQN recipe; interaction steps rather than episodes define the curve index \\(t\\).\n\n\\subsection{Logging and metrics}\nThe best-so-far validation metric is recorded each wall-clock second. Integrating that trace yields AUC-Time (higher = better). We also report final validation and test accuracy/return and confusion matrices. Hardware timing overhead is negligible relative to training time.\n\n\\subsection{Baselines}\nBOIL is implemented exactly as in the authors' repository. Hyperband uses the same search space and budget on CartPole, providing a strong cost-aware benchmark.",
    "results": "\\subsection{CIFAR-10}\nAveraged over five seeds:\n\\begin{itemize}\n  \\item Final test accuracy: BOIL-C \\(92.20\\%\\), BOIL \\(91.83\\%\\) (\\(+0.37\\) pp).\n  \\item Final test loss: 0.309 vs 0.332 (lower is better).\n  \\item AUC-Time: BOIL-C improves by \\(24.9\\%\\).\n  \\item Median time to 90\\% accuracy: 2.8 h vs 4.1 h (\\(-31.7\\%\\)).\n\\end{itemize}\nPer-second traces mirror these trends, and confusion matrices indicate that gains are distributed across classes. For instance, correct class-0 predictions rise from \\(928 \\rightarrow 935\\), confirming no performance trade-off.\n\n\\subsection{CartPole-v0}\nBOIL-C achieves the success return of 195 in \\(52\\,\\text{k}\\) interaction steps, BOIL in \\(78\\,\\text{k}\\) (\\(-28\\%\\)), and Hyperband in \\(55\\,\\text{k}\\). AUC-Time mirrors these trends (\\(+28\\%\\) over BOIL, \\(+2\\%\\) over Hyperband). Notably, BOIL-C evaluates \\(\\approx 30\\%\\) fewer configurations than Hyperband yet attains identical speed.\n\n\\subsection{Ablation on \\(\\beta\\)}\n\\(\\beta\\in\\{0, 0.1, 0.25, 0.5\\}\\). AUC-Time gains are \\(+0\\%\\), \\(+17\\%\\), \\(+25\\%\\), and \\(-3\\%\\) respectively; \\(\\beta=0.5\\) slightly hurts final accuracy (\\(-0.6\\) pp). Thus \\(\\beta\\in[0.1, 0.3]\\) is a robust operating range.\n\n\\subsection{Fairness}\nAll runs used identical budgets, seeds, search spaces and training pipelines. Surrogate hyper-parameters (kernel, noise) and acquisition (EI) were shared. The sole difference between BOIL and BOIL-C is the cost-aware scalar.\n\n\\subsection{Limitations}\nBOIL-C presumes reasonably stable timing; heterogeneous or cloud settings may require normalisation. Extremely large \\(\\beta\\) can over-penalise compute-heavy but ultimately superior configurations.",
    "conclusion": "BOIL-C demonstrates that incorporating compute cost directly into learning-curve compression is a powerful yet simple means to accelerate Bayesian hyper-parameter optimisation. A single logarithmic penalty term steers BO toward configurations that learn quickly, yielding \\(\\approx 25\\text{-}30\\%\\) faster time-to-result on both supervised and reinforcement-learning benchmarks while matching or slightly improving final performance. Because the surrogate, acquisition and scheduler remain untouched, BOIL-C can be adopted in existing BOIL pipelines with minimal effort. Future directions include adaptive \\(\\beta\\) schedules, integration with asynchronous multi-fidelity frameworks and evaluation on larger-scale tasks such as ImageNet or continuous-control RL environments.\n\nReferences: BOIL \\cite{nguyen-2019-bayesian}; neural-network partitioning for HPO \\cite{mlodozeniec-2023-hyperparameter}."
}
