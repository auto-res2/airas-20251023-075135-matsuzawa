
LLM Name: gpt-5-2025-08-07
Input:

You are a LaTeX expert.
Your task is to convert each section of a research paper into plain LaTeX **content only**, without including any section titles or metadata.

Below are the paper sections. For each one, convert only the **content** into LaTeX:

---
Section: title

One-Line Cost Awareness for BOIL: Faster Hyper-parameter Search via Learning-Curve Compression

---

---
Section: abstract

Bayesian Optimisation for Iterative Learning (BOIL) compresses every partial learning curve to a scalar that is modelled with a Gaussian process. The scalar depends only on the instantaneous validation score, so a configuration that needs 200 epochs to reach 90 % accuracy receives the same utility as one that needs 20. This indifference to wall-clock cost slows the search whenever ultimately good but slow-learning settings monopolise resources. We introduce BOIL-C, a cost-aware compression that leaves BOIL’s surrogate, acquisition function and optimisation loop untouched but adds a single term to the score: u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)), where s(·) is BOIL’s sigmoid, C(x,t) is cumulative training time and β∈. The logarithmic penalty favours configurations that learn quickly while retaining diminishing sensitivity to long runs. On CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN, BOIL-C reaches the same final accuracy/return as BOIL yet converges 30–40 % faster, improving the area-under-best-so-far curve with respect to time by ≈25 %. It matches or slightly exceeds Hyperband while requiring far fewer total runs, and paired t-tests confirm the gains are statistically significant. Because the change is literally one subtraction in the compression routine, BOIL-C is a practical drop-in replacement whenever compute efficiency matters.

---

---
Section: introduction

Hyper-parameter optimisation (HPO) remains a dominant consumer of compute in contemporary machine learning. The tension between limited budgets and ever-larger search spaces has stimulated methods that exploit information gleaned before a training run converges. Bayesian Optimisation for Iterative Learning (BOIL) exemplifies this trend: it compresses each partial learning curve to a scalar via a sigmoid transformation, then fits a Gaussian-process (GP) surrogate and chooses the next action with a standard acquisition function \cite{nguyen-2019-bayesian}. BOIL showed strong sample-efficiency on convolutional networks and deep reinforcement learning because its surrogate could already act on early accuracy gains.  Yet BOIL deliberately ignores how much compute was expended to obtain each measurement. Two configurations that both achieve 90 % validation accuracy receive identical utility even if one took ten times longer. Consequently, when slow yet high-performing configurations appear promising the optimiser may keep investing in them and postpone exploration of faster alternatives—a poor strategy under tight real-time or monetary budgets.

We argue that the root cause is not BOIL’s GP, kernel choice or acquisition function but the objective presented to the surrogate. We therefore introduce Cost-Aware Learning-Curve Compression (BOIL-C), a minimal change that augments BOIL’s scalar with an explicit logarithmic cost penalty. Formally we define u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)), where r(x,t) is the validation metric at step t, C(x,t) is cumulative wall-clock time and β controls how strongly compute is penalised. All remaining components—the GP with Matérn-52 kernel, expected improvement acquisition and Optuna-driven optimisation loop—remain unchanged. The modification is implemented by adding one line to BOIL’s compression routine, making adoption trivial.

We evaluate BOIL-C on two tasks representative of mainstream HPO practice. (1) CIFAR-10 classification with a 1.2 M-parameter four-layer CNN; we tune learning rate, batch size and dropout. (2) CartPole-v0 reinforcement learning with DQN, mirroring the task used in the BOIL paper. Each optimiser receives a strict 8 hour GPU budget and is run with five independent seeds. We compare BOIL-C to original BOIL and to Hyperband—a widely used cost-aware scheduler. Primary metrics are (i) final validation accuracy or return at budget exhaustion, and (ii) area under the best-so-far curve as a function of wall-clock time (AUC-Time), which directly rewards early progress.

Results show that BOIL-C attains 92.20 % final test accuracy on CIFAR-10 versus 91.83 % for BOIL, while requiring only 2.7 h to pass the 90 % threshold compared with 4.4 h for BOIL. AUC-Time improves by 25.3 % and edges out Hyperband, which itself needs many more short trials. On CartPole-v0 BOIL-C reaches the success threshold 40 % faster than BOIL and slightly faster than Hyperband, with identical final returns. Two-sided paired t-tests on seed-matched AUC-Time traces give p=0.004 (vision) and p=0.007 (RL), confirming statistical significance.

Contributions
• We expose compute-insensitivity as a core inefficiency of BOIL and formalise it as a missing argument in the compression function.
• We propose BOIL-C, a one-line, theoretically motivated correction that subtracts β·log(1+C) from BOIL’s score.
• Extensive experiments on vision and reinforcement learning tasks demonstrate that BOIL-C keeps BOIL’s final quality yet accelerates convergence by 30–40 % and improves AUC-Time by ≈25 %, matching or surpassing Hyperband with roughly half the number of runs.
• We release code and logs, and provide significance analyses that attribute the gains solely to the new cost-aware term.

Future work includes learning β jointly with m0 and g0 via marginal likelihood, exploring alternative concave cost penalties, extending to multi-resource settings and combining BOIL-C with single-run proxy-objective methods such as neural-network partitioning \cite{mlodozeniec-2023-hyperparameter}.

---

---
Section: related_work

Three research strands intersect with our contribution.  (i) Learning-curve modelling with Bayesian optimisation: BOIL pioneered the idea of compressing partial curves to scalars that a GP can regress on \cite{nguyen-2019-bayesian}. Subsequent work largely follows the same pattern but, like BOIL, focuses exclusively on performance and omits cost. BOIL-C is therefore orthogonal and can be integrated into any of these variants without altering their surrogates or acquisitions.  (ii) Bandit-style resource schedulers: Hyperband successively halves poorly performing trials and reallocates compute. It is explicitly cost-aware but eschews surrogate modelling, leading to many more total runs. Our experiments confirm that BOIL-C inherits BOIL’s sample-efficiency while narrowing—often eliminating—Hyperband’s advantage in wall-clock time.  (iii) Proxy objectives that bypass validation curves: Neural-network partitioning constructs an out-of-training-sample loss that can be optimised within a single run to tune hyper-parameters \cite{mlodozeniec-2023-hyperparameter}. While this line eliminates repeated training, it requires architectural partitioning and targets a different regime. BOIL-C instead retains the standard validation-based objective and merely reshapes it to reflect practitioner utility.

Compared with prior art, BOIL-C uniquely combines a global Bayesian surrogate with explicit compute awareness, achieved through a single subtraction rather than through scheduler logic or architectural changes. This minimalism allows it to be dropped into existing BOIL code bases with negligible engineering effort.

---

---
Section: background

We formalise the HPO setting as follows. A configuration x∈X specifies hyper-parameters such as learning rate or batch size. Running the training process for t steps yields a validation metric r(x,t) (accuracy for vision, average return for reinforcement learning) and incurs wall-clock cost c(x,t) in seconds. Cumulative cost is C(x,t)=∑_{i=1}^{t}c(x,i). Practitioners care about discovering configurations that achieve high validation scores quickly; we capture this preference through the best-so-far trajectory B(τ)=max_{x,t:wall-clock≤τ}r(x,t) and evaluate optimisers via the integral AUC-Time=∫_{0}^{budget}B(τ)dτ.

BOIL addresses this sequential decision problem by compressing each observation (x,t) into u_BOIL(x,t)=s(r(x,t);m0,g0), where s is a parametrised sigmoid learned by GP marginal likelihood. The GP then predicts u_BOIL for unseen x, and an acquisition function such as expected improvement determines which configuration and step to sample next. Crucially, u_BOIL ignores C(x,t); hence the surrogate treats two equally accurate but differently expensive observations as identical. In time-critical scenarios this mismatch causes inefficient allocation.

Alternative strategies include scheduler-based early stopping (e.g. Hyperband) and single-run proxy objectives (e.g. neural-network partitioning). While these methods do account for cost, they sacrifice either global modelling or require architectural rewrites. BOIL-C aims to inherit BOIL’s modelling strengths while embedding a succinct notion of cost.

---

---
Section: method

We retain BOIL’s sigmoid s(r;m0,g0) but redefine the scalar fed to the GP as
u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)).

Choice of penalty The logarithm is strictly increasing but concave, so early cost increments receive stronger penalties while very long runs are not suppressed excessively. When C(x,t)=0 the original BOIL score is recovered. β≥0 scales the penalty; in all experiments we simply fix β=0.25, demonstrating robustness without tuning.

Integration into BOIL Only the compression routine changes. All subsequent steps—storing observations, fitting the GP with a Matérn-52 kernel and 0.001 noise variance, computing expected improvement, and selecting actions—are unmodified. Thus any empirical gains can be attributed to the altered objective, not to broader system changes.

Interpretation Subtracting β·log(1+C) shifts the posterior mean for slow-learning configurations downward relative to fast ones with the same accuracy. Expected improvement therefore favours regions expected to yield rapid gains in s(r) at low additional cost, yet will still explore slower regions if their eventual s(r) is high enough to overcome the penalty. The concave form prevents pathological over-penalisation of long but genuinely superior runs.

Implementation listing A minimal Python patch replaces BOIL’s compression:
    scalar = sigmoid_score - beta * np.log1p(cumulative_cost)
No other lines change, underscoring the negligible engineering overhead.

---

---
Section: experimental_setup

Vision task CIFAR-10 images are pre-processed by random 32×32 crop with padding 4, random horizontal flip (p=0.5) and channel-wise normalisation. The model is a four-layer CNN with 64-128-256-256 channels followed by a 512-unit fully-connected layer; total parameters ≈1.2 M. Training uses SGD with momentum 0.9, weight decay 5×10⁻⁴ and cosine learning-rate decay for up to 200 epochs. The search space comprises learning rate ∈ (log-uniform), batch size ∈{32,64,128} and dropout ∈ (uniform).

Reinforcement-learning task CartPole-v0 with DQN follows the original BOIL setup: hyper-parameters tuned are learning rate and target-network update period. The environment solves when the 100-episode moving average return exceeds 195.

Optimisers compared (1) BOIL-C (β=0.25). (2) BOIL (original). (3) Hyperband (cost-aware baseline). BOIL and BOIL-C share the same GP (Matérn-52, noise 0.001) and expected improvement acquisition. All methods receive an identical 8 hour wall-clock budget on an NVIDIA A100 and are executed with five independent seeds.

Logging and metrics For every second we log the best-so-far validation metric; AUC-Time is computed by trapezoidal integration. We also record final validation accuracy/return at budget exhaustion and the time taken to reach predetermined thresholds (90 % accuracy for vision, 195 return for RL). Paired t-tests across seeds assess significance on AUC-Time.

---

---
Section: results

Vision (CIFAR-10) BOIL-C achieves 92.20 % final test accuracy versus 91.83 % for BOIL, a 0.37 pp absolute gain. More importantly, it reaches 90 % accuracy in 2.7 h, whereas BOIL needs 4.4 h (-39 %). AUC-Time increases from 0.884 to 0.922 (+25.3 %). Hyperband attains 0.918 and 92.1 % accuracy, so BOIL-C matches or slightly betters it while using roughly 40 % fewer trials.

Reinforcement learning (CartPole-v0) BOIL-C, BOIL and Hyperband all end at ≈200 average return, yet BOIL-C reaches the 195 threshold in 33 min, BOIL in 55 min and Hyperband in 36 min. AUC-Time improves by 26 % over BOIL.

Statistical analysis Two-sided paired t-tests on seed-matched AUC-Time give p=0.004 for CIFAR-10 and p=0.007 for CartPole, rejecting equality at α=0.05. Differences in final accuracy/return are not significant, as intended.

Ablation Although β is fixed, the observed gains suggest modest sensitivity; learning β dynamically is left for future work.

Limitations Excessive β could over-penalise and miss slow but ultimately superior configurations; conversely β→0 reduces BOIL-C to BOIL. The logarithmic form assumes diminishing concern for late-stage cost, which may not hold in all domains.

Figures
Figure 1: Confusion matrix for BOIL-C on CIFAR-10 test set; higher diagonal values indicate better accuracy (filename: proposed-Small-CNN-1.2M-CIFAR-10_confusion_matrix.pdf)
Figure 2: BOIL-C learning curve; best-so-far validation accuracy versus time, higher is better (filename: proposed-Small-CNN-1.2M-CIFAR-10_learning_curve.pdf)
Figure 3: Confusion matrix for BOIL on CIFAR-10 test set; higher diagonal values indicate better accuracy (filename: comparative-1-Small-CNN-1.2M-CIFAR-10_confusion_matrix.pdf)
Figure 4: BOIL learning curve; best-so-far validation accuracy versus time, higher is better (filename: comparative-1-Small-CNN-1.2M-CIFAR-10_learning_curve.pdf)
Figure 5: Final test accuracies for all methods; higher is better (filename: comparison_accuracy_bar_chart.pdf)
Figure 6: Distribution of final test accuracies across seeds; higher median is better (filename: comparison_accuracy_boxplot.pdf)
Figure 7: Relative improvement in key metrics over BOIL; higher bars are better (filename: comparison_relative_improvement_bar_chart.pdf)
Figure 8: Detailed metrics artifact (filename: metrics.json)
Figure 9: Aggregated metrics artifact (filename: aggregated_metrics.json)
Figure 10: Significance test statistics (filename: significance_tests.json)
Figure 11: Supplementary metrics artifact (filename: metrics.json)

---

---
Section: conclusion

We introduced BOIL-C, a one-line modification that endows BOIL with explicit awareness of wall-clock cost. By subtracting β·log(1+C) from BOIL’s sigmoid score, the GP surrogate is asked to model exactly the trade-off practitioners care about: performance achieved per unit time. Empirically, BOIL-C retains BOIL’s strong final accuracy and return yet converges 30–40 % faster, yielding ≈25 % higher AUC-Time and rivaling Hyperband with far fewer total runs. Paired statistical tests confirm the improvements are significant. Because the change touches only the compression function, any existing BOIL implementation can adopt BOIL-C with minimal effort. Future research will automate selection of β, investigate alternative concave penalties, extend the idea to multi-resource optimisation and fuse cost-aware compression with single-run proxy objectives such as neural-network partitioning \cite{mlodozeniec-2023-hyperparameter}. For practitioners bound by budgets or latency, BOIL-C offers an immediate, drop-in upgrade to BOIL’s efficiency without sacrificing its Bayesian strengths \cite{nguyen-2019-bayesian}.

---


## LaTeX Formatting Rules:
- Use \subsection{...} for any subsections within this section.
    - Subsection titles should be distinct from the section name;
    - Do not use '\subsection{  }', or other slight variations. Use more descriptive and unique titles.
    - Avoid excessive subdivision. If a subsection is brief or overlaps significantly with another, consider merging them for clarity and flow.

- For listing contributions, use the LaTeX \begin{itemize}...\end{itemize} format.
    - Each item should start with a short title in \textbf{...} format.
    - Avoid using -, *, or other Markdown bullet styles.

- When including tables, use the `tabularx` environment with `\textwidth` as the target width.
    - At least one column must use the `X` type to enable automatic width adjustment and line breaking.
    - Include `\hline` at the top, after the header, and at the bottom. Avoid vertical lines unless necessary.
    - To left-align content in `X` columns, define `
ewcolumntype{Y}{>{
aggedrightrraybackslash}X}` using the `array` package.

- When writing pseudocode, use the `algorithm` and `algorithmicx` LaTeX environments.
    - Only include pseudocode in the `Method` section. Pseudocode is not allowed in any other sections.
    - Prefer the `\begin{algorithmic}` environment using **lowercase commands** such as `\State`, `\For`, and `\If`, to ensure compatibility and clean formatting.
    - Pseudocode must represent actual algorithms or procedures with clear logic. Do not use pseudocode to simply rephrase narrative descriptions or repeat what has already been explained in text.
        - Good Example:
        ```latex
        \State Compute transformed tokens: \(	ilde{T} \leftarrow W\,T\)
        \State Update: \(T_{new} \leftarrow 	ilde{T} + \mu\,T_{prev}\)
        ```
- Figures and images are ONLY allowed in the "Results" section.
    - Use LaTeX float option `[H]` to force placement.

- All figures must be inserted using the following LaTeX format, using a `width` that reflects the filename:
    ```latex
    \includegraphics[width=\linewidth]{ images/filename.pdf }
    ```
    The `<appropriate-width>` must be selected based on the filename suffix:
    - If the filename ends with _pair1.pdf or _pair2.pdf, use 0.48\linewidth as the width of each subfigure environment and place the figures side by side using `subcaption` package.
    - Otherwise (default), use 0.7\linewidth

- **Escaping special characters**:
    - LaTeX special characters (`#`, `$`, `%`, `&`, `~`, `_`, `^`, `{`, `}`, `\`) must be escaped with a leading backslash when they appear in plain text (e.g., `data\_set`, `C\&C`).
    - Underscores **must always be escaped** (`\_`) outside math mode, even in filenames (e.g., memory\_profiler), code-style words, itemize lists, or citation contexts.

- Always use ASCII hyphens (`-`) instead of en-dashes (`–`) or em-dashes (`—`) to avoid spacing issues in hyphenated terms.
- Do not include any of these higher-level commands such as \documentclass{...}, \begin{document}, and \end{document}.
    - Additionally, avoid including section-specific commands such as \begin{abstract}, \section{  }, or any other similar environment definitions.
- Do not modify citation placeholders:
    - Citation placeholders appear in the format [citation_key], where citation_key contains underscores, numbers, and text (e.g., [vaswani_2017_attention], [smith_2023_deep]).
    - You must preserve these placeholders EXACTLY as they appear in the input text.
- If no LaTeX conversion is needed, output the content as-is without status messages like [Unchanged].
Output:
{
    "title": "One-Line Cost Awareness for BOIL: Faster Hyper-parameter Search via Learning-Curve Compression",
    "abstract": "Bayesian Optimisation for Iterative Learning (BOIL) compresses every partial learning curve to a scalar that is modelled with a Gaussian process. The scalar depends only on the instantaneous validation score, so a configuration that needs 200 epochs to reach 90\\% accuracy receives the same utility as one that needs 20. This indifference to wall-clock cost slows the search whenever ultimately good but slow-learning settings monopolise resources. We introduce BOIL-C, a cost-aware compression that leaves BOIL’s surrogate, acquisition function and optimisation loop untouched but adds a single term to the score: \\(u(x,t)=s(r(x,t);m_0,g_0)-\\beta\\cdot\\log(1+C(x,t))\\), where \\(s(\\cdot)\\) is BOIL’s sigmoid, \\(C(x,t)\\) is cumulative training time and \\(\\beta\\). The logarithmic penalty favours configurations that learn quickly while retaining diminishing sensitivity to long runs. On CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN, BOIL-C reaches the same final accuracy/return as BOIL yet converges 30-40\\% faster, improving the area-under-best-so-far curve with respect to time by \\(\\approx 25\\%\\). It matches or slightly exceeds Hyperband while requiring far fewer total runs, and paired t-tests confirm the gains are statistically significant. Because the change is literally one subtraction in the compression routine, BOIL-C is a practical drop-in replacement whenever compute efficiency matters.",
    "introduction": "Hyper-parameter optimisation (HPO) remains a dominant consumer of compute in contemporary machine learning. The tension between limited budgets and ever-larger search spaces has stimulated methods that exploit information gleaned before a training run converges. Bayesian Optimisation for Iterative Learning (BOIL) exemplifies this trend: it compresses each partial learning curve to a scalar via a sigmoid transformation, then fits a Gaussian-process (GP) surrogate and chooses the next action with a standard acquisition function \\cite{nguyen-2019-bayesian}. BOIL showed strong sample-efficiency on convolutional networks and deep reinforcement learning because its surrogate could already act on early accuracy gains. Yet BOIL deliberately ignores how much compute was expended to obtain each measurement. Two configurations that both achieve 90\\% validation accuracy receive identical utility even if one took ten times longer. Consequently, when slow yet high-performing configurations appear promising the optimiser may keep investing in them and postpone exploration of faster alternatives - a poor strategy under tight real-time or monetary budgets.\n\nWe argue that the root cause is not BOIL’s GP, kernel choice or acquisition function but the objective presented to the surrogate. We therefore introduce Cost-Aware Learning-Curve Compression (BOIL-C), a minimal change that augments BOIL’s scalar with an explicit logarithmic cost penalty. Formally we define \\(u(x,t)=s(r(x,t);m_0,g_0)-\\beta\\cdot\\log(1+C(x,t))\\), where \\(r(x,t)\\) is the validation metric at step \\(t\\), \\(C(x,t)\\) is cumulative wall-clock time and \\(\\beta\\) controls how strongly compute is penalised. All remaining components - the GP with Mat\\'ern-52 kernel, expected improvement acquisition and Optuna-driven optimisation loop - remain unchanged. The modification is implemented by adding one line to BOIL’s compression routine, making adoption trivial.\n\nWe evaluate BOIL-C on two tasks representative of mainstream HPO practice. (1) CIFAR-10 classification with a 1.2 M-parameter four-layer CNN; we tune learning rate, batch size and dropout. (2) CartPole-v0 reinforcement learning with DQN, mirroring the task used in the BOIL paper. Each optimiser receives a strict 8 hour GPU budget and is run with five independent seeds. We compare BOIL-C to original BOIL and to Hyperband - a widely used cost-aware scheduler. Primary metrics are (i) final validation accuracy or return at budget exhaustion, and (ii) area under the best-so-far curve as a function of wall-clock time (AUC-Time), which directly rewards early progress.\n\nResults show that BOIL-C attains 92.20\\% final test accuracy on CIFAR-10 versus 91.83\\% for BOIL, while requiring only 2.7 h to pass the 90\\% threshold compared with 4.4 h for BOIL. AUC-Time improves by 25.3\\% and edges out Hyperband, which itself needs many more short trials. On CartPole-v0 BOIL-C reaches the success threshold 40\\% faster than BOIL and slightly faster than Hyperband, with identical final returns. Two-sided paired t-tests on seed-matched AUC-Time traces give \\(p=0.004\\) (vision) and \\(p=0.007\\) (RL), confirming statistical significance.\n\n\\subsection{Contributions}\n\\begin{itemize}\n  \\item \\textbf{Compute-insensitivity in BOIL:} We expose compute-insensitivity as a core inefficiency of BOIL and formalise it as a missing argument in the compression function.\n  \\item \\textbf{BOIL-C formulation:} We propose BOIL-C, a one-line, theoretically motivated correction that subtracts \\(\\beta\\cdot\\log(1+C)\\) from BOIL’s score.\n  \\item \\textbf{Empirical gains:} Extensive experiments on vision and reinforcement learning tasks demonstrate that BOIL-C keeps BOIL’s final quality yet accelerates convergence by 30-40\\% and improves AUC-Time by \\(\\approx 25\\%\\), matching or surpassing Hyperband with roughly half the number of runs.\n  \\item \\textbf{Resources and analysis:} We release code and logs, and provide significance analyses that attribute the gains solely to the new cost-aware term.\n\\end{itemize}\n\n\\subsection{Future Work}\nFuture work includes learning \\(\\beta\\) jointly with \\(m_0\\) and \\(g_0\\) via marginal likelihood, exploring alternative concave cost penalties, extending to multi-resource settings and combining BOIL-C with single-run proxy-objective methods such as neural-network partitioning \\cite{mlodozeniec-2023-hyperparameter}.",
    "related_work": "Three research strands intersect with our contribution. (i) Learning-curve modelling with Bayesian optimisation: BOIL pioneered the idea of compressing partial curves to scalars that a GP can regress on \\cite{nguyen-2019-bayesian}. Subsequent work largely follows the same pattern but, like BOIL, focuses exclusively on performance and omits cost. BOIL-C is therefore orthogonal and can be integrated into any of these variants without altering their surrogates or acquisitions. (ii) Bandit-style resource schedulers: Hyperband successively halves poorly performing trials and reallocates compute. It is explicitly cost-aware but eschews surrogate modelling, leading to many more total runs. Our experiments confirm that BOIL-C inherits BOIL’s sample-efficiency while narrowing - often eliminating - Hyperband’s advantage in wall-clock time. (iii) Proxy objectives that bypass validation curves: Neural-network partitioning constructs an out-of-training-sample loss that can be optimised within a single run to tune hyper-parameters \\cite{mlodozeniec-2023-hyperparameter}. While this line eliminates repeated training, it requires architectural partitioning and targets a different regime. BOIL-C instead retains the standard validation-based objective and merely reshapes it to reflect practitioner utility.\n\nCompared with prior art, BOIL-C uniquely combines a global Bayesian surrogate with explicit compute awareness, achieved through a single subtraction rather than through scheduler logic or architectural changes. This minimalism allows it to be dropped into existing BOIL code bases with negligible engineering effort.",
    "background": "We formalise the HPO setting as follows. A configuration \\(x\\in\\mathcal{X}\\) specifies hyper-parameters such as learning rate or batch size. Running the training process for \\(t\\) steps yields a validation metric \\(r(x,t)\\) (accuracy for vision, average return for reinforcement learning) and incurs wall-clock cost \\(c(x,t)\\) in seconds. Cumulative cost is \\(C(x,t)=\\sum_{i=1}^{t}c(x,i)\\). Practitioners care about discovering configurations that achieve high validation scores quickly; we capture this preference through the best-so-far trajectory \\(B(\\tau)=\\max_{x,t:\\,\\text{wall-clock}\\le\\tau} r(x,t)\\) and evaluate optimisers via the integral \\(\\text{AUC-Time}=\\int_{0}^{\\text{budget}} B(\\tau)\\,d\\tau\\).\n\nBOIL addresses this sequential decision problem by compressing each observation \\((x,t)\\) into \\(u_{\\mathrm{BOIL}}(x,t)=s(r(x,t);m_0,g_0)\\), where \\(s\\) is a parametrised sigmoid learned by GP marginal likelihood. The GP then predicts \\(u_{\\mathrm{BOIL}}\\) for unseen \\(x\\), and an acquisition function such as expected improvement determines which configuration and step to sample next. Crucially, \\(u_{\\mathrm{BOIL}}\\) ignores \\(C(x,t)\\); hence the surrogate treats two equally accurate but differently expensive observations as identical. In time-critical scenarios this mismatch causes inefficient allocation.\n\nAlternative strategies include scheduler-based early stopping (e.g. Hyperband) and single-run proxy objectives (e.g. neural-network partitioning). While these methods do account for cost, they sacrifice either global modelling or require architectural rewrites. BOIL-C aims to inherit BOIL’s modelling strengths while embedding a succinct notion of cost.",
    "method": "We retain BOIL’s sigmoid \\(s(r;m_0,g_0)\\) but redefine the scalar fed to the GP as\n\\[ u(x,t) = s\\big(r(x,t); m_0, g_0\\big) - \\beta\\,\\log\\big(1 + C(x,t)\\big). \\]\n\n\\subsection{Choice of Penalty}\nThe logarithm is strictly increasing but concave, so early cost increments receive stronger penalties while very long runs are not suppressed excessively. When \\(C(x,t)=0\\) the original BOIL score is recovered. \\(\\beta\\ge 0\\) scales the penalty; in all experiments we simply fix \\(\\beta=0.25\\), demonstrating robustness without tuning.\n\n\\subsection{Integration into BOIL}\nOnly the compression routine changes. All subsequent steps - storing observations, fitting the GP with a Mat\\'ern-52 kernel and 0.001 noise variance, computing expected improvement, and selecting actions - are unmodified. Thus any empirical gains can be attributed to the altered objective, not to broader system changes.\n\n\\subsection{Interpretation}\nSubtracting \\(\\beta\\cdot\\log(1+C)\\) shifts the posterior mean for slow-learning configurations downward relative to fast ones with the same accuracy. Expected improvement therefore favours regions expected to yield rapid gains in \\(s(r)\\) at low additional cost, yet will still explore slower regions if their eventual \\(s(r)\\) is high enough to overcome the penalty. The concave form prevents pathological over-penalisation of long but genuinely superior runs.\n\n\\subsection{Implementation Listing}\nA minimal Python patch replaces BOIL’s compression: \\texttt{scalar = sigmoid\\_score - beta * np.log1p(cumulative\\_cost)}. No other lines change, underscoring the negligible engineering overhead.\n\n\\begin{algorithm}\n\\caption{Cost-aware compression used by BOIL-C}\n\\begin{algorithmic}\n  \\State \\textbf{Input:} configuration \\(x\\), step \\(t\\); validation metric \\(r(x,t)\\); cumulative cost \\(C(x,t)\\); sigmoid parameters \\(m_0,g_0\\); penalty \\(\\beta\\)\n  \\State Compute sigmoid score: \\(s \\leftarrow s\\big(r(x,t); m_0, g_0\\big)\\)\n  \\State Compute cost penalty: \\(p \\leftarrow \\beta\\,\\log\\big(1 + C(x,t)\\big)\\)\n  \\State Return compressed scalar: \\(u(x,t) \\leftarrow s - p\\)\n\\end{algorithmic}\n\\end{algorithm}",
    "experimental_setup": "\\subsection{Vision Task: CIFAR-10}\nCIFAR-10 images are pre-processed by random \\(32\\times 32\\) crop with padding 4, random horizontal flip (\\(p=0.5\\)) and channel-wise normalisation. The model is a four-layer CNN with 64-128-256-256 channels followed by a 512-unit fully-connected layer; total parameters \\(\\approx\\)1.2 M. Training uses SGD with momentum 0.9, weight decay \\(5\\times 10^{-4}\\) and cosine learning-rate decay for up to 200 epochs. The search space comprises learning rate \\(\\in\\) (log-uniform), batch size \\(\\in\\{32,64,128\\}\\) and dropout \\(\\in\\) (uniform).\n\n\\subsection{Reinforcement Learning Task: CartPole-v0}\nCartPole-v0 with DQN follows the original BOIL setup: hyper-parameters tuned are learning rate and target-network update period. The environment solves when the 100-episode moving average return exceeds 195.\n\n\\subsection{Optimisers Compared}\n(1) BOIL-C (\\(\\beta=0.25\\)). (2) BOIL (original). (3) Hyperband (cost-aware baseline). BOIL and BOIL-C share the same GP (Mat\\'ern-52, noise 0.001) and expected improvement acquisition. All methods receive an identical 8 hour wall-clock budget on an NVIDIA A100 and are executed with five independent seeds.\n\n\\subsection{Logging and Metrics}\nFor every second we log the best-so-far validation metric; AUC-Time is computed by trapezoidal integration. We also record final validation accuracy/return at budget exhaustion and the time taken to reach predetermined thresholds (90\\% accuracy for vision, 195 return for RL). Paired t-tests across seeds assess significance on AUC-Time.",
    "results": "\\subsection{Vision (CIFAR-10)}\nBOIL-C achieves 92.20\\% final test accuracy versus 91.83\\% for BOIL, a 0.37 pp absolute gain. More importantly, it reaches 90\\% accuracy in 2.7 h, whereas BOIL needs 4.4 h (-39\\%). AUC-Time increases from 0.884 to 0.922 (+25.3\\%). Hyperband attains 0.918 and 92.1\\% accuracy, so BOIL-C matches or slightly betters it while using roughly 40\\% fewer trials.\n\n\\subsection{Reinforcement Learning (CartPole-v0)}\nBOIL-C, BOIL and Hyperband all end at \\(\\approx 200\\) average return, yet BOIL-C reaches the 195 threshold in 33 min, BOIL in 55 min and Hyperband in 36 min. AUC-Time improves by 26\\% over BOIL.\n\n\\subsection{Statistical Analysis}\nTwo-sided paired t-tests on seed-matched AUC-Time give \\(p=0.004\\) for CIFAR-10 and \\(p=0.007\\) for CartPole, rejecting equality at \\(\\alpha=0.05\\). Differences in final accuracy/return are not significant, as intended.\n\n\\subsection{Ablation and Limitations}\nAlthough \\(\\beta\\) is fixed, the observed gains suggest modest sensitivity; learning \\(\\beta\\) dynamically is left for future work. Excessive \\(\\beta\\) could over-penalise and miss slow but ultimately superior configurations; conversely \\(\\beta\\to 0\\) reduces BOIL-C to BOIL. The logarithmic form assumes diminishing concern for late-stage cost, which may not hold in all domains.\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/proposed-Small-CNN-1.2M-CIFAR-10\\_confusion\\_matrix.pdf }\n  \\caption{Confusion matrix for BOIL-C on CIFAR-10 test set; higher diagonal values indicate better accuracy.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/proposed-Small-CNN-1.2M-CIFAR-10\\_learning\\_curve.pdf }\n  \\caption{BOIL-C learning curve; best-so-far validation accuracy versus time, higher is better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparative-1-Small-CNN-1.2M-CIFAR-10\\_confusion\\_matrix.pdf }\n  \\caption{Confusion matrix for BOIL on CIFAR-10 test set; higher diagonal values indicate better accuracy.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparative-1-Small-CNN-1.2M-CIFAR-10\\_learning\\_curve.pdf }\n  \\caption{BOIL learning curve; best-so-far validation accuracy versus time, higher is better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparison\\_accuracy\\_bar\\_chart.pdf }\n  \\caption{Final test accuracies for all methods; higher is better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparison\\_accuracy\\_boxplot.pdf }\n  \\caption{Distribution of final test accuracies across seeds; higher median is better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparison\\_relative\\_improvement\\_bar\\_chart.pdf }\n  \\caption{Relative improvement in key metrics over BOIL; higher bars are better.}\n\\end{figure}\n\nFigure 8: Detailed metrics artifact (filename: metrics.json)\n\nFigure 9: Aggregated metrics artifact (filename: aggregated\\_metrics.json)\n\nFigure 10: Significance test statistics (filename: significance\\_tests.json)\n\nFigure 11: Supplementary metrics artifact (filename: metrics.json)",
    "conclusion": "We introduced BOIL-C, a one-line modification that endows BOIL with explicit awareness of wall-clock cost. By subtracting \\(\\beta\\cdot\\log(1+C)\\) from BOIL’s sigmoid score, the GP surrogate is asked to model exactly the trade-off practitioners care about: performance achieved per unit time. Empirically, BOIL-C retains BOIL’s strong final accuracy and return yet converges 30-40\\% faster, yielding \\(\\approx 25\\%\\) higher AUC-Time and rivaling Hyperband with far fewer total runs. Paired statistical tests confirm the improvements are significant. Because the change touches only the compression function, any existing BOIL implementation can adopt BOIL-C with minimal effort. Future research will automate selection of \\(\\beta\\), investigate alternative concave penalties, extend the idea to multi-resource optimisation and fuse cost-aware compression with single-run proxy objectives such as neural-network partitioning \\cite{mlodozeniec-2023-hyperparameter}. For practitioners bound by budgets or latency, BOIL-C offers an immediate, drop-in upgrade to BOIL’s efficiency without sacrificing its Bayesian strengths \\cite{nguyen-2019-bayesian}."
}
