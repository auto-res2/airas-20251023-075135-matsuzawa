
LLM Name: gpt-5-2025-08-07
Input:

You are a LaTeX expert.
Your task is to convert each section of a research paper into plain LaTeX **content only**, without including any section titles or metadata.

Below are the paper sections. For each one, convert only the **content** into LaTeX:

---
Section: title

BOIL-C: Cost-Aware Learning-Curve Compression for Faster Bayesian Hyper-Parameter Optimisation

---

---
Section: abstract

Bayesian Optimisation for Iterative Learning (BOIL) compresses every partial learning curve into a single sigmoid score that ignores how long the curve took to obtain. Consequently the optimiser may keep sampling slow-learning but ultimately strong configurations, wasting wall-clock time \cite{nguyen-2019-bayesian}. We introduce BOIL-C, a one-line modification that subtracts a logarithmic penalty on cumulative compute from BOIL’s score, u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)). The surrogate model, acquisition function and optimisation loop remain untouched, but the search is now biased towards configurations that reach high accuracy quickly. Experiments on CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN confirm that BOIL-C maintains or slightly improves final performance while reducing time-to-result. With an identical eight-hour budget and five independent seeds BOIL-C attains 92.20 % test accuracy on CIFAR-10 versus 91.83 % for BOIL, improves area-under-curve (AUC) of best-so-far accuracy over time by ≈25 %, and reaches the 90 % threshold 31 % sooner. On CartPole BOIL-C achieves the target return in 52 k steps, beating BOIL (78 k) and matching Hyperband while evaluating fewer configurations. An ablation over β shows a broad effective range with β≈0.25. These results demonstrate that injecting a simple cost term into curve compression delivers substantial wall-clock savings without sacrificing quality.

---

---
Section: introduction

Hyper-parameter optimisation (HPO) is indispensable for modern machine-learning systems yet remains constrained by its wall-clock cost. Bayesian Optimisation (BO) alleviates the burden by modelling the performance surface and guiding exploration, and BOIL accelerates this process further by feeding the surrogate a single scalar that summarises partial learning curves \cite{nguyen-2019-bayesian}. While elegant, BOIL’s compression is compute-agnostic: a run that needs 20 epochs and one that needs 200 epochs to reach the same accuracy receive identical utility. As a result the optimiser may repeatedly allocate budget to slow-learning configurations, delaying progress. 

We close this gap by proposing BOIL-C, a cost-aware compression that penalises cumulative training time while preserving BOIL’s architecture. Given validation metric r(x,t) and cumulative wall-clock cost C(x,t) up to time t, the new scalar is

u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)).

The logarithmic term grows quickly at first, encouraging fast learners, and saturates later, avoiding excessive punishment of long but necessary training. Because only the scalar changes, all of BOIL’s downstream machinery—Gaussian-process (GP) surrogate, expected-improvement acquisition, Optuna scheduler—remains intact.

We evaluate BOIL-C on CIFAR-10 image classification with a small CNN and on CartPole-v0 reinforcement learning with DQN, comparing against the original BOIL and, on RL, the cost-aware scheduler Hyperband. We report (i) the AUC of best-so-far performance versus wall-clock time, a direct measure of time-efficiency, and (ii) final test metrics at budget exhaustion. We also study the impact of the cost weight β.

Contributions.
• A principled yet minimal cost-aware compression that drops into any BOIL implementation with a single line of code.
• A thorough empirical study showing that BOIL-C improves AUC-time by ≈25 % and shortens time-to-target by more than 30 % while retaining (and slightly improving) final accuracy.
• An ablation revealing a broad, stable regime for β, easing practical adoption.
• Discussion of how curve-level cost awareness complements alternative HPO paradigms such as resource schedulers and marginal-likelihood methods \cite{mlodozeniec-2023-hyperparameter}.

The remainder of the paper reviews related work, formalises the problem, details BOIL-C, describes the experimental setup, reports results and concludes with limitations and future directions.

---

---
Section: related_work

Learning-curve exploitation. BOIL models partial curves via a fixed-shape sigmoid and uses the resulting scalar in a GP surrogate \cite{nguyen-2019-bayesian}. Several follow-up works vary the surrogate or acquisition but keep the compute-agnostic compression. BOIL-C differs by leaving the model intact and modifying only the information passed to it.

Cost-aware schedulers. Hyperband and its successors allocate resources dynamically, terminating poor runs early. These methods are explicitly time-aware but typically need many concurrent evaluations and do not benefit from GP-based uncertainty estimates. Our RL study compares BOIL-C to Hyperband, showing similar speed yet higher sample efficiency.

Objective reformulation. Partitioning-based approaches estimate marginal likelihoods to optimise hyper-parameters without validation sets \cite{mlodozeniec-2023-hyperparameter}. Such strategies are complementary: BOIL-C could summarise partitioned training curves just as it summarises full ones.

In summary, previous BOIL-style methods ignore compute, bandit schedulers ignore surrogate structure, and partitioning approaches change the objective rather than the optimiser. BOIL-C uniquely injects resource awareness into the scalar representation while keeping the proven BOIL pipeline.

---

---
Section: background

Let X denote the hyper-parameter space. Training a configuration x∈X yields a time-indexed validation metric r(x,t) after t epochs (or steps). BOIL maps the pair (x,t) to a scalar s(r(x,t);m0,g0)=1/(1+exp(−(r−m0)/g0)) learned by marginal likelihood, so that a GP surrogate f approximates u≈s. An acquisition function a selects the next configuration to evaluate. 

Problem definition. Given a time budget B seconds, select configurations sequentially so as to maximise final validation/test performance and to improve that performance as quickly as possible. Existing BOIL treats two runs with equal r but different compute equally; we instead define cumulative cost C(x,t)=∑_{i≤t}c(x,i) (seconds per epoch) and penalise it in the scalar fed to the GP.

Assumptions. Wall-clock per iteration is recorded reliably; sigmoid parameters (m0,g0) are learned as in BOIL; the GP uses a Matérn-5/2 kernel with noise 0.001; acquisition is expected improvement. The only new hyper-parameter is β∈.

---

---
Section: method

BOIL-C computes

u(x,t)=s(r(x,t);m0,g0)−β·log(1+C(x,t)),

with s(·) the BOIL sigmoid and C(x,t) cumulative seconds. The logarithm ensures diminishing returns: doubling compute late in training costs less utility than early doubling. The subtraction simply shifts the target of the GP; all update rules, hyper-parameter learning and acquisition optimisation remain unchanged.

Implementation is trivial:

sigmoid_score = 1/(1+exp(−(r_t−m0)/g0))
scalar_for_gp = sigmoid_score − β*np.log1p(cumulative_cost)

Only this line replaces BOIL’s original compression. Because the remainder of the code base is unaffected, practitioners can adopt BOIL-C with minimal effort.

Selecting β. We fix β=0.25 by default, informed by an ablation (§Results). In principle β can be optimised jointly with (m0,g0) via marginal likelihood or treated as a hyper-parameter in a two-level BO loop.

---

---
Section: experimental_setup

Common optimiser settings. All methods employ a GP surrogate with a Matérn-5/2 kernel and noise 0.001, trained by maximising marginal likelihood, and use expected improvement as acquisition. Optuna’s TPE sampler generates 60 trials; a median pruner discards runs whose scalar u is below the median of completed trials. Each optimiser receives an eight-hour wall-clock budget and is repeated with five random seeds on identical NVIDIA A100 GPUs.

CIFAR-10 image classification. Model: four convolutional layers (channels 64-128-256-256) followed by a 512-unit fully-connected layer, ReLU activations and 0.25 dropout; ≈1.2 M parameters. Training uses SGD (momentum 0.9, weight decay 5 · 10⁻⁴), cosine learning-rate schedule, 200 epochs and batch size 64. Data augmentation is standard random crop and horizontal flip followed by normalisation. Search space: learning-rate log-uniform in , batch size ∈{32,64,128}, dropout uniform in .

CartPole-v0 reinforcement learning. We reuse BOIL’s DQN setup, tuning learning rate and target-network update period. The performance metric is average episodic return; the optimiser logs best-so-far return every second.

Baselines. We compare BOIL-C to BOIL on both tasks and to Hyperband on CartPole. All hyper-parameters, budgets and logging frequencies are matched.

---

---
Section: results

CIFAR-10 results. Table 1 summarises the key numbers.

• Final accuracy. BOIL-C attains 92.20 % test accuracy versus 91.83 % for BOIL (Δ = +0.37 pp). Test loss decreases from 0.332 to 0.309.
• Time-efficiency. The normalised AUC of best-so-far accuracy rises from 0.738 to 0.922 (+24.9 %). BOIL-C reaches 90 % accuracy in 2.8 h median versus 4.1 h for BOIL (−31.7 %).
• Confusion matrices (Figures 2 and 4) show consistent class-wise improvements; e.g. class 0 correct predictions increase from 928 to 935.

CartPole-v0 results. BOIL-C achieves the target return of 195 in 52 k interaction steps on average. BOIL requires 78 k steps; Hyperband needs 55 k. BOIL-C’s AUC-time improves by 28 % over BOIL and is within +2 % of Hyperband while running ≈30 % fewer trials.

Ablation on β. β∈{0,0.1,0.25,0.5}. Relative AUC-time gains on CIFAR-10 are +0 %, +17 %, +25 % and +23 %; β≥0.5 slightly degrades final accuracy (−0.6 pp). Hence β≈0.25 is a good default with a wide tolerance.

Limitations. BOIL-C assumes stable timing measurements; in highly variable clusters the compute signal may be noisy, though the log term mitigates extremes. β adds one knob, albeit an easy one to tune.

Figures.
Figure 1: Summary metrics for all experiments (filename: metrics.json). Higher AUC and accuracy, lower loss indicate better performance.
Figure 2: Confusion matrix for BOIL-C on CIFAR-10 (filename: proposed-Small-CNN-1.2M-CIFAR-10_confusion_matrix.pdf). Higher diagonal values are better.
Figure 3: Learning-curve trace for BOIL-C on CIFAR-10 (filename: proposed-Small-CNN-1.2M-CIFAR-10_learning_curve.pdf). Higher curves are better.
Figure 4: Confusion matrix for BOIL on CIFAR-10 (filename: comparative-1-Small-CNN-1.2M-CIFAR-10_confusion_matrix.pdf). Higher diagonal values are better.
Figure 5: Learning-curve trace for BOIL on CIFAR-10 (filename: comparative-1-Small-CNN-1.2M-CIFAR-10_learning_curve.pdf). Higher curves are better.
Figure 6: Aggregated metrics across seeds (filename: aggregated_metrics.json). Higher absolute and relative improvements are better.
Figure 7: Accuracy comparison bar chart (filename: comparison_accuracy_bar_chart.pdf). Higher bars are better.
Figure 8: Accuracy comparison boxplot (filename: comparison_accuracy_boxplot.pdf). Higher medians and quartiles indicate better performance.
Figure 9: Relative improvement chart (filename: comparison_relative_improvement_bar_chart.pdf). Higher bars indicate larger gains.
Figure 10: Statistical significance results (filename: significance_tests.json). Lower p-values indicate stronger evidence.


---

---
Section: conclusion

BOIL-C equips BOIL’s elegant learning-curve compression with an explicit notion of time, using a single logarithmic penalty term. Across image classification and reinforcement learning the modification yields ≈25 % higher AUC-time and >30 % faster convergence while matching or slightly improving final accuracy. Because only one line of code changes, the method offers an immediate drop-in benefit to practitioners relying on BOIL.

Future work will automate the choice of β via hierarchical Bayesian treatment, extend the penalty to other resource metrics such as energy or memory, and explore integration with multi-fidelity BO and partitioning-based HPO methods \cite{mlodozeniec-2023-hyperparameter}. More broadly, our results highlight that embedding resource awareness directly into the representation of partial evaluations can steer any surrogate-based optimiser toward faster, more economical search trajectories.

Acknowledgements. We thank the authors of BOIL for open-sourcing their code and Optuna for providing the optimisation framework.

References. \cite{nguyen-2019-bayesian,mlodozeniec-2023-hyperparameter}

---


## LaTeX Formatting Rules:
- Use \subsection{...} for any subsections within this section.
    - Subsection titles should be distinct from the section name;
    - Do not use '\subsection{  }', or other slight variations. Use more descriptive and unique titles.
    - Avoid excessive subdivision. If a subsection is brief or overlaps significantly with another, consider merging them for clarity and flow.

- For listing contributions, use the LaTeX \begin{itemize}...\end{itemize} format.
    - Each item should start with a short title in \textbf{...} format.
    - Avoid using -, *, or other Markdown bullet styles.

- When including tables, use the `tabularx` environment with `\textwidth` as the target width.
    - At least one column must use the `X` type to enable automatic width adjustment and line breaking.
    - Include `\hline` at the top, after the header, and at the bottom. Avoid vertical lines unless necessary.
    - To left-align content in `X` columns, define `
ewcolumntype{Y}{>{
aggedrightrraybackslash}X}` using the `array` package.

- When writing pseudocode, use the `algorithm` and `algorithmicx` LaTeX environments.
    - Only include pseudocode in the `Method` section. Pseudocode is not allowed in any other sections.
    - Prefer the `\begin{algorithmic}` environment using **lowercase commands** such as `\State`, `\For`, and `\If`, to ensure compatibility and clean formatting.
    - Pseudocode must represent actual algorithms or procedures with clear logic. Do not use pseudocode to simply rephrase narrative descriptions or repeat what has already been explained in text.
        - Good Example:
        ```latex
        \State Compute transformed tokens: \(	ilde{T} \leftarrow W\,T\)
        \State Update: \(T_{new} \leftarrow 	ilde{T} + \mu\,T_{prev}\)
        ```
- Figures and images are ONLY allowed in the "Results" section.
    - Use LaTeX float option `[H]` to force placement.

- All figures must be inserted using the following LaTeX format, using a `width` that reflects the filename:
    ```latex
    \includegraphics[width=\linewidth]{ images/filename.pdf }
    ```
    The `<appropriate-width>` must be selected based on the filename suffix:
    - If the filename ends with _pair1.pdf or _pair2.pdf, use 0.48\linewidth as the width of each subfigure environment and place the figures side by side using `subcaption` package.
    - Otherwise (default), use 0.7\linewidth

- **Escaping special characters**:
    - LaTeX special characters (`#`, `$`, `%`, `&`, `~`, `_`, `^`, `{`, `}`, `\`) must be escaped with a leading backslash when they appear in plain text (e.g., `data\_set`, `C\&C`).
    - Underscores **must always be escaped** (`\_`) outside math mode, even in filenames (e.g., memory\_profiler), code-style words, itemize lists, or citation contexts.

- Always use ASCII hyphens (`-`) instead of en-dashes (`–`) or em-dashes (`—`) to avoid spacing issues in hyphenated terms.
- Do not include any of these higher-level commands such as \documentclass{...}, \begin{document}, and \end{document}.
    - Additionally, avoid including section-specific commands such as \begin{abstract}, \section{  }, or any other similar environment definitions.
- Do not modify citation placeholders:
    - Citation placeholders appear in the format [citation_key], where citation_key contains underscores, numbers, and text (e.g., [vaswani_2017_attention], [smith_2023_deep]).
    - You must preserve these placeholders EXACTLY as they appear in the input text.
- If no LaTeX conversion is needed, output the content as-is without status messages like [Unchanged].
Output:
{
    "title": "BOIL-C: Cost-Aware Learning-Curve Compression for Faster Bayesian Hyper-Parameter Optimisation",
    "abstract": "Bayesian Optimisation for Iterative Learning (BOIL) compresses every partial learning curve into a single sigmoid score that ignores how long the curve took to obtain. Consequently the optimiser may keep sampling slow-learning but ultimately strong configurations, wasting wall-clock time \\cite{nguyen-2019-bayesian}. We introduce BOIL-C, a one-line modification that subtracts a logarithmic penalty on cumulative compute from BOIL's score, \\(u(x,t)=s(r(x,t);m_0,g_0)-\\beta\\cdot\\log(1+C(x,t))\\). The surrogate model, acquisition function and optimisation loop remain untouched, but the search is now biased towards configurations that reach high accuracy quickly. Experiments on CIFAR-10 with a 1.2 M-parameter CNN and on CartPole-v0 with DQN confirm that BOIL-C maintains or slightly improves final performance while reducing time-to-result. With an identical eight-hour budget and five independent seeds BOIL-C attains 92.20 \\% test accuracy on CIFAR-10 versus 91.83 \\% for BOIL, improves area-under-curve (AUC) of best-so-far accuracy over time by \\(\\approx 25\\ \\%\\), and reaches the 90 \\% threshold 31 \\% sooner. On CartPole BOIL-C achieves the target return in 52 k steps, beating BOIL (78 k) and matching Hyperband while evaluating fewer configurations. An ablation over \\(\\beta\\) shows a broad effective range with \\(\\beta\\approx 0.25\\). These results demonstrate that injecting a simple cost term into curve compression delivers substantial wall-clock savings without sacrificing quality.",
    "introduction": "Hyper-parameter optimisation (HPO) is indispensable for modern machine-learning systems yet remains constrained by its wall-clock cost. Bayesian Optimisation (BO) alleviates the burden by modelling the performance surface and guiding exploration, and BOIL accelerates this process further by feeding the surrogate a single scalar that summarises partial learning curves \\cite{nguyen-2019-bayesian}. While elegant, BOIL's compression is compute-agnostic: a run that needs 20 epochs and one that needs 200 epochs to reach the same accuracy receive identical utility. As a result the optimiser may repeatedly allocate budget to slow-learning configurations, delaying progress.\n\n\\subsection{Cost-aware curve compression}\nWe close this gap by proposing BOIL-C, a cost-aware compression that penalises cumulative training time while preserving BOIL's architecture. Given validation metric \\(r(x,t)\\) and cumulative wall-clock cost \\(C(x,t)\\) up to time \\(t\\), the new scalar is\n\\[\n u(x,t)=s(r(x,t);m_0,g_0)-\\beta\\cdot\\log(1+C(x,t)).\n\\]\nThe logarithmic term grows quickly at first, encouraging fast learners, and saturates later, avoiding excessive punishment of long but necessary training. Because only the scalar changes, all of BOIL's downstream machinery—Gaussian-process (GP) surrogate, expected-improvement acquisition, Optuna scheduler—remains intact.\n\n\\subsection{Evaluation overview}\nWe evaluate BOIL-C on CIFAR-10 image classification with a small CNN and on CartPole-v0 reinforcement learning with DQN, comparing against the original BOIL and, on RL, the cost-aware scheduler Hyperband. We report (i) the AUC of best-so-far performance versus wall-clock time, a direct measure of time-efficiency, and (ii) final test metrics at budget exhaustion. We also study the impact of the cost weight \\(\\beta\\).\n\n\\subsection{Contributions and summary}\n\\begin{itemize}\n  \\item \\textbf{Minimal drop-in modification:} A principled yet minimal cost-aware compression that drops into any BOIL implementation with a single line of code.\n  \\item \\textbf{Empirical gains in time-efficiency:} A thorough empirical study showing that BOIL-C improves AUC-time by \\(\\approx 25\\ \\%\\) and shortens time-to-target by more than 30 \\% while retaining (and slightly improving) final accuracy.\n  \\item \\textbf{Stable cost-weight selection:} An ablation revealing a broad, stable regime for \\(\\beta\\), easing practical adoption.\n  \\item \\textbf{Complementary to other HPO paradigms:} Discussion of how curve-level cost awareness complements alternative HPO paradigms such as resource schedulers and marginal-likelihood methods \\cite{mlodozeniec-2023-hyperparameter}.\n\\end{itemize}\n\nThe remainder of the paper reviews related work, formalises the problem, details BOIL-C, describes the experimental setup, reports results and concludes with limitations and future directions.",
    "related_work": "\\subsection{Learning-curve exploitation}\nBOIL models partial curves via a fixed-shape sigmoid and uses the resulting scalar in a GP surrogate \\cite{nguyen-2019-bayesian}. Several follow-up works vary the surrogate or acquisition but keep the compute-agnostic compression. BOIL-C differs by leaving the model intact and modifying only the information passed to it.\n\n\\subsection{Cost-aware schedulers}\nHyperband and its successors allocate resources dynamically, terminating poor runs early. These methods are explicitly time-aware but typically need many concurrent evaluations and do not benefit from GP-based uncertainty estimates. Our RL study compares BOIL-C to Hyperband, showing similar speed yet higher sample efficiency.\n\n\\subsection{Objective reformulation}\nPartitioning-based approaches estimate marginal likelihoods to optimise hyper-parameters without validation sets \\cite{mlodozeniec-2023-hyperparameter}. Such strategies are complementary: BOIL-C could summarise partitioned training curves just as it summarises full ones.\n\n\\subsection{Summary}\nIn summary, previous BOIL-style methods ignore compute, bandit schedulers ignore surrogate structure, and partitioning approaches change the objective rather than the optimiser. BOIL-C uniquely injects resource awareness into the scalar representation while keeping the proven BOIL pipeline.",
    "background": "Let \\(X\\) denote the hyper-parameter space. Training a configuration \\(x\\in X\\) yields a time-indexed validation metric \\(r(x,t)\\) after \\(t\\) epochs (or steps). BOIL maps the pair \\((x,t)\\) to a scalar \\(s(r(x,t);m_0,g_0)=1/(1+\\exp(-(r-m_0)/g_0))\\) learned by marginal likelihood, so that a GP surrogate \\(f\\) approximates \\(u\\approx s\\). An acquisition function \\(a\\) selects the next configuration to evaluate.\n\n\\subsection{Problem definition}\nGiven a time budget \\(B\\) seconds, select configurations sequentially so as to maximise final validation/test performance and to improve that performance as quickly as possible. Existing BOIL treats two runs with equal \\(r\\) but different compute equally; we instead define cumulative cost \\(C(x,t)=\\sum_{i\\le t} c(x,i)\\) (seconds per epoch) and penalise it in the scalar fed to the GP.\n\n\\subsection{Assumptions}\nWall-clock per iteration is recorded reliably; sigmoid parameters \\((m_0,g_0)\\) are learned as in BOIL; the GP uses a Mat\\'ern-5/2 kernel with noise 0.001; acquisition is expected improvement. The only new hyper-parameter is \\(\\beta\\in\\.\\)",
    "method": "\\subsection{Cost-aware scalar}\nBOIL-C computes\n\\[\n u(x,t)=s(r(x,t);m_0,g_0)-\\beta\\cdot\\log(1+C(x,t)),\n\\]\nwith \\(s(\\cdot)\\) the BOIL sigmoid and \\(C(x,t)\\) cumulative seconds. The logarithm ensures diminishing returns: doubling compute late in training costs less utility than early doubling. The subtraction simply shifts the target of the GP; all update rules, hyper-parameter learning and acquisition optimisation remain unchanged.\n\n\\subsection{Implementation detail}\nImplementation is trivial:\n\n\\noindent\\texttt{sigmoid\\_score = 1/(1+exp(-(r\\_t-m0)/g0))}\\\\\n\\texttt{scalar\\_for\\_gp = sigmoid\\_score - \\$\\beta\\$*np.log1p(cumulative\\_cost)}\n\nOnly this line replaces BOIL's original compression. Because the remainder of the code base is unaffected, practitioners can adopt BOIL-C with minimal effort.\n\n\\subsection{Choosing the cost weight}\nSelecting \\(\\beta\\). We fix \\(\\beta=0.25\\) by default, informed by an ablation (\\S Results). In principle \\(\\beta\\) can be optimised jointly with \\((m_0,g_0)\\) via marginal likelihood or treated as a hyper-parameter in a two-level BO loop.",
    "experimental_setup": "\\subsection{Common optimiser settings}\nAll methods employ a GP surrogate with a Mat\\'ern-5/2 kernel and noise 0.001, trained by maximising marginal likelihood, and use expected improvement as acquisition. Optuna's TPE sampler generates 60 trials; a median pruner discards runs whose scalar \\(u\\) is below the median of completed trials. Each optimiser receives an eight-hour wall-clock budget and is repeated with five random seeds on identical NVIDIA A100 GPUs.\n\n\\subsection{CIFAR-10 image classification}\nModel: four convolutional layers (channels 64-128-256-256) followed by a 512-unit fully-connected layer, ReLU activations and 0.25 dropout; \\(\\approx\\)1.2 M parameters. Training uses SGD (momentum 0.9, weight decay \\(5 \\cdot 10^{-4}\\)), cosine learning-rate schedule, 200 epochs and batch size 64. Data augmentation is standard random crop and horizontal flip followed by normalisation. Search space: learning-rate log-uniform in , batch size \\(\\in\\{32,64,128\\}\\), dropout uniform in .\n\n\\subsection{CartPole-v0 reinforcement learning}\nWe reuse BOIL's DQN setup, tuning learning rate and target-network update period. The performance metric is average episodic return; the optimiser logs best-so-far return every second.\n\n\\subsection{Baselines}\nWe compare BOIL-C to BOIL on both tasks and to Hyperband on CartPole. All hyper-parameters, budgets and logging frequencies are matched.",
    "results": "\\subsection{CIFAR-10 classification}\nTable 1 summarises the key numbers.\n\\begin{itemize}\n  \\item \\textbf{Final accuracy:} BOIL-C attains 92.20 \\% test accuracy versus 91.83 \\% for BOIL (\\(\\Delta = +0.37\\) pp). Test loss decreases from 0.332 to 0.309.\n  \\item \\textbf{Time-efficiency:} The normalised AUC of best-so-far accuracy rises from 0.738 to 0.922 (+24.9 \\%). BOIL-C reaches 90 \\% accuracy in 2.8 h median versus 4.1 h for BOIL (\\(-31.7\\ \\%\\)).\n  \\item \\textbf{Confusion matrices:} Figures 2 and 4 show consistent class-wise improvements; e.g. class 0 correct predictions increase from 928 to 935.\n\\end{itemize}\n\n\\subsection{CartPole-v0 reinforcement learning}\nBOIL-C achieves the target return of 195 in 52 k interaction steps on average. BOIL requires 78 k steps; Hyperband needs 55 k. BOIL-C's AUC-time improves by 28 \\% over BOIL and is within +2 \\% of Hyperband while running \\(\\approx\\)30 \\% fewer trials.\n\n\\subsection{Ablation on \\(\\beta\\)}\n\\(\\beta\\in\\{0,0.1,0.25,0.5\\}\\). Relative AUC-time gains on CIFAR-10 are +0 \\%, +17 \\%, +25 \\% and +23 \\%; \\(\\beta\\ge 0.5\\) slightly degrades final accuracy (\\(-0.6\\) pp). Hence \\(\\beta\\approx 0.25\\) is a good default with a wide tolerance.\n\n\\subsection{Limitations}\nBOIL-C assumes stable timing measurements; in highly variable clusters the compute signal may be noisy, though the log term mitigates extremes. \\(\\beta\\) adds one knob, albeit an easy one to tune.\n\n\\subsection{Figures}\nFigure 1: Summary metrics for all experiments (filename: metrics.json). Higher AUC and accuracy, lower loss indicate better performance.\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/proposed-Small-CNN-1.2M-CIFAR-10\\_confusion\\_matrix.pdf }\n  \\caption{Confusion matrix for BOIL-C on CIFAR-10. Higher diagonal values are better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/proposed-Small-CNN-1.2M-CIFAR-10\\_learning\\_curve.pdf }\n  \\caption{Learning-curve trace for BOIL-C on CIFAR-10. Higher curves are better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparative-1-Small-CNN-1.2M-CIFAR-10\\_confusion\\_matrix.pdf }\n  \\caption{Confusion matrix for BOIL on CIFAR-10. Higher diagonal values are better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparative-1-Small-CNN-1.2M-CIFAR-10\\_learning\\_curve.pdf }\n  \\caption{Learning-curve trace for BOIL on CIFAR-10. Higher curves are better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparison\\_accuracy\\_bar\\_chart.pdf }\n  \\caption{Accuracy comparison bar chart. Higher bars are better.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparison\\_accuracy\\_boxplot.pdf }\n  \\caption{Accuracy comparison boxplot. Higher medians and quartiles indicate better performance.}\n\\end{figure}\n\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=0.7\\linewidth]{ images/comparison\\_relative\\_improvement\\_bar\\_chart.pdf }\n  \\caption{Relative improvement chart. Higher bars indicate larger gains.}\n\\end{figure}\n\nFigure 6: Aggregated metrics across seeds (filename: aggregated\\_metrics.json). Higher absolute and relative improvements are better.\n\nFigure 10: Statistical significance results (filename: significance\\_tests.json). Lower p-values indicate stronger evidence.",
    "conclusion": "BOIL-C equips BOIL's elegant learning-curve compression with an explicit notion of time, using a single logarithmic penalty term. Across image classification and reinforcement learning the modification yields \\(\\approx 25\\ \\%\\) higher AUC-time and \\(>30\\ \\%\\) faster convergence while matching or slightly improving final accuracy. Because only one line of code changes, the method offers an immediate drop-in benefit to practitioners relying on BOIL.\n\nFuture work will automate the choice of \\(\\beta\\) via hierarchical Bayesian treatment, extend the penalty to other resource metrics such as energy or memory, and explore integration with multi-fidelity BO and partitioning-based HPO methods \\cite{mlodozeniec-2023-hyperparameter}. More broadly, our results highlight that embedding resource awareness directly into the representation of partial evaluations can steer any surrogate-based optimiser toward faster, more economical search trajectories.\n\nAcknowledgements. We thank the authors of BOIL for open-sourcing their code and Optuna for providing the optimisation framework.\n\nReferences. \\cite{nguyen-2019-bayesian,mlodozeniec-2023-hyperparameter}"
}
